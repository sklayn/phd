---
title: "Biodiversity of macrozoobenthic communities - 2"
date: "2017-11-02"
output: 
  html_notebook:
    theme: paper
---

## Biodiversity, taxonomic distinctness & graphical community analyses  
This is a continuation of the community analyses started in part 1. Includes the selection of more sophisticated descriptive community analyses of biodiversity, again applied on the 3 separate datasets.  

*** 
  Some setup, to make this notebook stand-alone.
```{r setup, include = FALSE}
library(knitr)
knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 2, .1, 2))  # smaller margin on top
})

# set knitr options for knitting code into the report.
opts_chunk$set(cache = TRUE, # save results so that code blocks aren't re-run unless code changes
               autodep = TRUE, # ..or unless a relevant earlier code block changed
               cache.comments = FALSE, # don't re-run if the only thing that changed was the comments
               highlight = TRUE, 
               small.mar = TRUE)
```
  Define the working subdirectories.
```{r workspace_setup}
data.dir <- "data"    # input data files
functions.dir <- "R"  # functions & scripts
save.dir <- "output"  # clean data, output from models & more complex calculations
figures.dir <- "figs" # plots & figures 
```
  Import functions.
```{r import_custom_functions}
source(file.path(functions.dir, "alpha_diversity.R"))
```
  
  Import the necessary libraries.  
```{r import_packages, message = FALSE}
library(vegan)
library(tidyverse)
library(viridis)
```
  Organize some commonly-used ggplot2 modifications into a more convenient (and less repetitive) format.
```{r custom_ggplot_settings_helpers}
## ggplot settings & things that I keep reusing
# ggplot_theme <- list(
#   theme_bw(),
#   theme(element_text(family = "Times"))
# )

## helper to adjust ggplot text size & avoid repetitions 
text_size <- function(text.x = NULL,
                      text.y = NULL,
                      title.x = NULL,
                      title.y = NULL,
                      legend.text = NULL,
                      legend.title = NULL, 
                      strip.x = NULL, 
                      strip.y = NULL) {
  theme(axis.text.x = element_text(size = text.x),
        axis.text.y = element_text(size = text.y),
        axis.title.x = element_text(size = title.x),
        axis.title.y = element_text(size = title.y),
        legend.text = element_text(size = legend.text), 
        legend.title = element_text(size = legend.title), 
        strip.text.x = element_text(size = strip.x), 
        strip.text.y = element_text(size = strip.y)
        )
  }
```
***
#### Macrozoobenthic communities in the sandy sediments of Burgas Bay (2013-2014)
Import the zoobenthic abundance & biomass data - as an exception, from the cleaned & saved datasets, to avoid (most of) the cleaning steps. 
```{r zoo_data_sand_import, message = FALSE, results = FALSE}
## dimensions should be 54 x 205 (5 metadata + 200 species columns); all species columns should be numeric.
zoo.abnd.sand <- read_csv(file.path(save.dir, "abnd_sand_orig_clean.csv"))

## same for biomass; same expected structure as the abundance
zoo.biomass.sand <- read_csv(file.path(save.dir, "biomass_sand_orig_clean.csv"))
```
  Convert columns to the proper type, arrange the datasets by station, etc.
```{r clean_zoo_data_sand, results = FALSE}
zoo.abnd.sand <- zoo.abnd.sand %>% 
  mutate(station = factor(station, levels = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva"))) %>%
  arrange(station, year, month)

zoo.biomass.sand <- zoo.biomass.sand %>% 
  mutate(station = factor(station, levels = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva"))) %>%
  arrange(station, year, month)
```
  Remove all species not present in the datasets (= all-0 columns). 
```{r clean_zoo_data_sand_2, results = FALSE}
## result should have dimensions 54 x 152 (147 species + 5 metadata columns) 
zoo.abnd.sand <- zoo.abnd.sand %>% 
  gather(key = species, value = sp_count, -c(station:replicate)) %>% 
  group_by(species) %>% 
  filter(sp_count > 0) %>%
  spread(species, sp_count, fill = 0)

zoo.biomass.sand <- zoo.biomass.sand %>% 
  gather(key = species, value = sp_biomass, -c(station:replicate)) %>% 
  group_by(species) %>% 
  filter(sp_biomass > 0) %>%
  spread(species, sp_biomass, fill = 0)
```
  
##### Alpha diversity indices  
All of the following can be calculated using package vegan. 
  + species richness S  
  + Shannon-Wiener biodiversity index H' (log2) - quantifies the probability that any two species drawn from the community are different - measure of entropy, NOT diversity! Therefore doesn't behave linearly. Actually measures the level of disorder in the system (more disorder = more diversity).    
  + Pielou evenness index J' - - level of dominance in the community. Close to 1 - the abundance is more evenly distrbuted among the species; close to 0 - one or several species largely dominate in abundance over the others.    
  + effective Shannon diversity (= corresponding Hill number) - to allow a meaningful comparison of diversity, not of entropy. Effective numbers impose a linear transformation on Shannon diversity - represent the number of equally abundant species necessary to produce the observed value of diversity. Range from 1 to S, where a value of S would indicate all species are present and in equal abundances.  
```{r alpha_diversity_sand}
## uses custom function for convenience - has to be imported first! 
alpha.div.sand <- zoo.abnd.sand %>%
  select(-c(station:replicate)) %>%
  alpha_diversity()

## add the metadata columns (row order is not changed, so possible) 
(alpha.div.sand <- bind_cols(zoo.abnd.sand %>% select(station:replicate), 
                            alpha.div.sand)
)
```
  Summarize these diversity indices by station & year.
```{r summarize_alpha_diversity_sand}
## might be a good place to eventually learn how to use the functions from package sjPlot for printing pretty (and easy!) tables...   
alpha.div.sand %>% 
  group_by(station, year) %>%
  summarise(h_mean = mean(shannon_h), h_sd = sd(shannon_h), 
            j_mean = mean(evenness_j), j_sd = sd(evenness_j),
            h_eff_mean = mean(h_effective), h_eff_sd = sd(h_effective)
            )
```
  
2. Species accumulation curves - see how species are added when the number of samples (sites) increases. Usually used to see if the sampling effort is adequate & captures most of the diversity in the study area.  
```{r sp_accumulation_curves_sand}
sac.sand <- specaccum(select(zoo.abnd.sand, -c(station:replicate)))

plot(sac.sand, 
     xlab = "Samples", ylab = "Cumulative species richness", 
     ci.type = "polygon", ci.col = "light blue")
```
  About 10 samples seem to be enough to capture most of the biodiversity in the study area (in terms of species richness) - this is where the curve starts to smooth out (slope < 1). In my dataset, there are 9 samples/station - could be considered enough.  
  NB IF this method is applied correctly, since the samples are not independent but in fact represent replicates at each station.  
  
##### Species pool  
The species pool is the total extrapolated number of species in the study area (various estimates used here). Used to estimate the number of **unobserved species**. The functions assume that the number of unobserved species is related to he number of rare species (= seen only once or twice).     
```{r sp_pool_sand}
## this function is based on incidences in sample sites - presence/absence data; gives a single estimate for a collection of sample sites
specpool(select(zoo.abnd.sand, -c(station:replicate)), 
         pool = zoo.abnd.sand$station, 
         smallsample = TRUE)

## this function is quantitative - based on abundances on single sample site
estimateR(select(zoo.abnd.sand, -c(station:replicate)))
```
  Now let's do it for the whole dataset. 
```{r sp_pool_total_sand}
specpool(select(zoo.abnd.sand, -c(station:replicate)), 
         smallsample = TRUE)
```
  Looks good: based on the most severe estimate (second-order jacknife), the dataset captures about 77 % of the species pool, and based on the most forgiving one (bootstrap) - about 91 %.  
  
##### Taxonomic distance & diversity  
  Simple diversity measures do not distinguish between species. However, in the real world, species relationships (phylogenetic, taxonomic, functional..) matter, and could carry important ecologcial information.    
  For these analyses, a master species list for the whole study area is needed. For the Black Sea, it was compiled using the Catalogue of Black Sea Fauna & its 2 updates, as well as other, more recent inventories (full references & details in Materials & methods).  
```{r import_master_taxonomic_list}
## NB imported with row names on purpose, otherwise later some vegan functions fail! 
master.tax.list <- read.csv(file = file.path(data.dir, "td_zoo_taxonomy.csv"), header = TRUE, row.names = 1)
```
  Now we'll calculate the **taxonomic distance** for the dataset.
```{r tax_distance_sand}
## calculate the taxonomic distance for the master species list, using variable step - scaling according to reduction in number of classes when going up in the tax. tree (if almost all genera have only 1 species, it makes no big difference if 2 individuals belong to a different species or a different genus). 
tax.dist.sand <- taxa2dist(master.tax.list, varstep = TRUE)

## calculate the taxonomic distinctness indices for the abundance dataset, and print it to examine (its built-in print method is actually better than mine, after later conversions to tibble, etc.)
(tax.distinctness.sand <- taxondive(select(zoo.abnd.sand, -c(station:replicate)), tax.dist.sand)
)

## get the summary - includes a significance test on Delta+
summary(tax.distinctness.sand)

# ## convert the taxonomic distinctness indices list to tibble
# tax.distinctness.sand <- as_tibble(lapply(tax.distinctness.sand, 
#                                           function(x) {vals <- x; return(vals)}))  
# 
# ## add in the metadata columns
# tax.distinctness.sand <- bind_cols(select(zoo.abnd.sand, station:replicate), tax.distinctness.sand)

## construct the funnel plots w/ 95% confidence limits based on the master species list. On the plus side, this shit only has to be done once, then can be reused for all 3 datasets (it's the same study area hence the same master species list). 

## initiate empty matrix to hold the simulation results
sim.list.names <- seq(from = 10, to = 150, by = 5) 
sim.tib <- matrix(NA, nrow = 999, ncol = length(sim.list.names))
colnames(sim.tib) <- sim.list.names

simulate_Dplus <- function(master.list, tax.dist.mat, species) {
  ## helper calculating Dplus for a simulated community sampled at random from the master species list for the study area   
  
  ## simulate a possible community of the specified size from the master species list for the study area
  sim.community <- dplyr::sample_n(master.list, size = species, replace = FALSE)
  
  ## convert to a matrix, to use in vegan function taxondive 
  sim.community.mat <- matrix(1, nrow = 1, ncol = nrow(sim.community))
  colnames(sim.community.mat) <- row.names(sim.community)
  
  ## calculate & extract Dplus for the simulated community, suppressing the messages related to dimension mismatch with the master list 
  dplus <- suppressMessages(vegan::taxondive(sim.community.mat, tax.dist.mat)$Dplus)
  
  return(dplus)
}

## some jumping through hoops to run this in parallel
library(parallel)
core.clust <- makeCluster(detectCores() - 3, type = "FORK")

## generate the Dplus values for each simulated dataset - using the parallel versions of the functions
sim.tib <- t(parApply(core.clust, sim.tib, 1, function(y) {
  sapply(sim.list.names, function(x) simulate_Dplus(master.tax.list, tax.dist.sand, species = x))
}))

## ALWAYS stop cluster afterwards!
stopCluster(core.clust)

## see where the bottleneck is
library(profvis)
profvis({
t(apply(sim.tib[1:100, 1:5], 1, function(y) {
  sapply(sim.list.names, function(x) simulate_Dplus(master.tax.list, tax.dist.sand, species = x))
}))
})

```
  Summarize the taxonomic distinctness indices by station.
```{r}
# aggregate taxonomic distinctness indices by station and year
tax.dist.table$stations <- reorder.factor(tax.dist.table$stations, 
                                            new.order = stations.sand)
tax.dist.summary <- ddply(tax.dist.table, .(stations), 
                          colwise(mean, .cols = is.numeric))
```
  




##### Graphical analyses  
  **Diversity profiles** are a graphical representation of the shape of the community. They show how the perceived diversity changes as the emphasis shifts from common to rare species - we can judge their respective contributions in the community composition.  
  Not sure if I'll use them in the thesis (most likely not), but I'm including the calculation and graphs here, because I think they're neat and I like them.  
```{r diversity_profiles_sand}
div.profiles.sand <- diversity_profiles(select(zoo.abnd.sand, -c(station:replicate)))

## plot them, too

```

  It's possible to calculate **weighted diversity profiles** by including a measure of similarity between species - for instance, taxonomic distance between them. This approach allows for a lot more meaningful ecological and biodiversity comparisons (Leinster & Cobbold, 2012).  
```{r weighted_diversity_profiles_sand}

```
  
