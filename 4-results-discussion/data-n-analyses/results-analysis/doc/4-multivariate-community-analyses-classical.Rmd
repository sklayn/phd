---
title: "Multivariate analyses of community structure (classical)"
date: "2018-08-06"
output: 
 html_notebook: 
  theme: paper
---

This notebook contains all (classical) multivariate analyses of zoobenthic community structure: MDS, envfit, ANOSIM & SIMPER and friends.  
All my notebooks are intended to be as self-contained as possible, so there will be a relatively repetitive setup/data import/preparation part.  

***  

Setup!
```{r setup, include = FALSE}
library(knitr)

knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 2, .1, 2))  # smaller margin on top
})

## set the working directory to one up (all notebooks - kept in their own subdirectory within the project directory).
opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

## set knitr options for knitting code into the report.
opts_chunk$set(cache = TRUE, # save results so that code blocks aren't re-run unless code changes
               autodep = TRUE, # ..or unless a relevant earlier code block changed
               cache.comments = FALSE, # don't re-run if the only thing that changed was the comments
               highlight = TRUE, 
               small.mar = TRUE)
```

Define the working subdirectories.  
```{r workspace_setup}
## print the working directory, just to be on the safe side
paste("You are here: ", getwd())

data.dir <- "data"    # input data files
functions.dir <- "R"  # functions & scripts
save.dir <- "output"  # clean data, output from models & more complex calculations
figures.dir <- "figs" # plots & figures 
```

Import libraries.  
```{r import_packages, results = FALSE}
library(here) # painless relative paths to subdurectories, etc.
library(tidyverse) # data manipulation, cleaning, aggregation
library(viridis) # smart & pretty colour schemes
library(vegan) # functions for multivariate analyses in ecology 
```

Organize some commonly-used ggplot2 modifications into a more convenient (and less repetitive) format. One day, I MUST figure out the proper way to set the theme..    
```{r custom_ggplot_settings_helpers}
## ggplot settings & things that I keep reusing
# ggplot_theme <- list(
#   theme_bw(),
#   theme(element_text(family = "Times"))
# )

## always use black-and-white theme
theme_set(theme_bw())

## helper to adjust ggplot text size & avoid repetitions 
text_size <- function(text.x = NULL,
                      text.y = NULL,
                      title.x = NULL,
                      title.y = NULL,
                      legend.text = NULL,
                      legend.title = NULL, 
                      strip.x = NULL, 
                      strip.y = NULL) {
  theme(axis.text.x = element_text(size = text.x),
        axis.text.y = element_text(size = text.y),
        axis.title.x = element_text(size = title.x),
        axis.title.y = element_text(size = title.y),
        legend.text = element_text(size = legend.text), 
        legend.title = element_text(size = legend.title), 
        strip.text.x = element_text(size = strip.x), 
        strip.text.y = element_text(size = strip.y)
        )
}

```

Import some custom functions for MDS, envfit and ordisurf plotting in ggplot (or just plain easier and prettier plotting).  
```{r import_custom_functions}
source(here(functions.dir, "plot_mds_revised.R")) # plot MDS in ggplot; extract envfit scores and overlay on MDS plot in ggplot
source(here(functions.dir, "p_adjust_envfit.R")) # apply Bonferroni correction for multiple comparisons on envfit results - adjusted p-values
source(here(functions.dir, "plot_ordisurf.R")) # extract ordisurf scores; plot ordisurf in base R
source(here(functions.dir, "simper_within_group_2.R")) # SIMPER for within-group species contributions
```

***  

#### Sand stations (Burgas Bay, 2013-2014)  
Import zoobenthic abundance data (cleaned and prepared).  
```{r import_zoo_abnd_sand}
zoo.abnd.sand <- read_csv(here(save.dir, "abnd_sand_orig_clean.csv"))

## convert station to factor (better safe than sorry later, when the stations are not plotted in the order I want them)
(zoo.abnd.sand <- zoo.abnd.sand %>% 
    mutate(station = factor(station, levels = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva")))
)
```

##### **Ordination (nMDS) on sand stations.**  
These are all functions from library vegan.  
```{r mds_zoo_sand}
## the vegan MDS function transforms the data (fourth root) and applies Bray-Curtis dissimilarity by default.   
mds.sand <- metaMDS(zoo.abnd.sand %>% select(-c(station:replicate)), 
                    distance = "bray", 
                    autotransform = TRUE)

mds.sand
```

Examine the quality of the MDS representation..  
```{r mds_quality_sand}
## stressplot
stressplot(mds.sand)

## goodness-of-fit plot 

## first plot the nMDS ordination with sites
plot(mds.sand, display = 'sites', type = 't', main = 'Goodness of fit') 

## then, add the points with size reflecting goodness of fit (smaller = better fit)
points(mds.sand, display = 'sites', cex = goodness(mds.sand)*200) 

```

Well it's not perfect, but could be lived with.. Let's call it good enough.  
The stress is 0.15, which is fairly close to, but still below the limit (0.2) suggested in the Primer manual. 
Save the MDS for the sand stations.  
```{r save_mds_sand}
write_rds(mds.sand, 
          here(save.dir, "mds_sand.RDS"))
```

Now, let's make a pretty plot in ggplot..  
Previously, I had written a custom MDS plotting function for ggplot, which I'm going to review and optimize now (in another notebook kept especially for that).. 
```{r plot_mds_sand}
## plot the MDS, using my custom ggplot function
plot.mds.sand <- plot_mds(mds.sand, groups = zoo.abnd.sand %>% pull(station))

## change colour scheme & labels
(plot.mds.sand <- plot.mds.sand + 
    scale_color_brewer(palette = "Set2", name = "station", 
                       labels = paste0("S", as.numeric((unique(zoo.abnd.sand %>% pull(station))))))
)
```

Well, to me at least it appears that there are **4 groups** on the MDS: 1 - combining stations Kraimorie and Chukalya; 2 - Akin, 3 - Agalina, 4 - combining Sozopol and Paraskeva (although this last one is a bit loosely associated).  
To confirm this, the classical method is to test the observed grouping with ANOSIM. Another more visual test is to overlay a classification tree made with the same data on the ordination, but I don't think I'll bother with it.   

A more statistical approach to determine the optimal number of clusters is to also run **cluster analysis (via k-means clustering)** on the abundance data.
```{r kmeans_sand} 
## with Hellinger transformation of the data (because k-means uses Euclidean distances which don't work well for ecological data).
kmeans.casc.sand <- cascadeKM(decostand(zoo.abnd.sand %>% select(-c(station:replicate)),
                                        method = "hellinger"),
                              inf.gr = 3, sup.gr = 6) ## I want at least 3 groups and at most 6 (the number of stations)

plot(kmeans.casc.sand, sortg = TRUE)
```

This result suggests 5 groups (based on the highest value of the Calinski criterion - plot on the right), but 4 groups is not much worse.. It seems more logical to use 4, because of the oridnation results: 1) S3-Akin + 2) S1-Kraimorie-S2-Chukalya + 3) S5-Agalina + 4) S4-Sozopol-S6-Paraskeva.  
Get these clusters - we'll check them later for validity & relationship with the explanatory environmental variables.   
```{r kmeans_clusters_sand}
## get the partition in 4 groups 
kmeans.clusters.sand <- as.vector(kmeans.casc.sand$partition[, 2])
```

##### **Envfit - sand stations.**   
Envfit can be used to determine which environmental parameters correlate best with the ordination (and thus explain best the observed dissimilarities in the zoobenthic community structure between stations).  
As per the PCA results, from the water column parameters, I'll use the most significant ones (best correlated with PCA axes): LUSI, secchi, seston, PO4, NH4, NO3 + all sediment parameters (except the most inter-correlated): TOM, moisture content, gravel and silt_clay.  
First, import the environmental parameters (from the cleaned files).  
For the water column, I'll use the long-term means wherever possible (and repeat each value 9 times per station to match the number of zoobenthic replicates that I have).   
```{r import_water_data_sand}
water.sand.all <- read_csv(here(save.dir, "water_column_summary_LT.csv"))

(water.sand <- water.sand.all %>% 
    ## filter only the sand stations
    filter(station %in% c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva")) %>% 
    
    ## get only the variables we want (significant in PCA)
    select(station, NH4_mean, NO3_mean, PO4_mean, seston_mean, secchi_mean) %>% 
    
    ## remove "mean" from the column names, purely for cosmetics
    rename_at(vars(-station), 
              funs(gsub(pattern = "_mean", replacement =  "", x = .)))
)
```

Now import LUSI and add it to this tibble.  
```{r import_lusi_sand}
lusi <- read_csv(here(save.dir, "lusi_st.csv"))

## only get LUSI for the sand stations and make a new tibble with all environmental data 
(env.data.sand <- inner_join(water.sand,
                             lusi %>% select(-watershed),
                             by = "station")
)
```
Repeat each row 9 times to match the zoobenthic community data (stupid, but needs to be done).  
```{r duplicate_rows_env_data_sand}
(env.data.sand <- env.data.sand %>% 
   slice(rep(1:n(), each = 9))
)
```

Goody! On to the sediment data.  
```{r import_sediments_sand}
sediments.all <- read_csv(here(save.dir, "sediments_imputed_sand.csv"))

(sediments.sand <- sediments.all %>% 
    ## select only the desired subset of variables (reduced list for PCA)
    select(station, TOM, moisture_content, gravel, silt_clay) %>% 
    
    ## repeat each row 3 times (there are 3 distinct values for the sediments, because there were 3 samplings)
    slice(rep(1:n(), each = 3))
)
```

Merge the sediment tibble with the rest of the environmental data.  
```{r merge_env_data_sand}
(env.data.sand <- bind_cols(env.data.sand,
                            sediments.sand %>% select(-station)) %>% 
   ## convert station to factor
   mutate(station = factor(station, levels = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva")))
)
```

All right, ready to roll!  
Envfit of all this shit & the sand MDS..  
```{r envfit_sand}
envfit.sand <- envfit(mds.sand,
                      env.data.sand %>% select(-station))

## apply the p-value correction.. 
(envfit.sand.adj <- p_adjust_envfit(envfit.sand)
)

## save it for posterity
write_rds(envfit.sand.adj, 
          here(save.dir, "envfit_sand_adj.RDS"))
```

Plot the envfit vectors over the MDS of the sand stations.  
```{r plot_envfit_sand}
## extract the envfit scores - easier format for plotting in ggplot.. 
(envfit.scrs.sand <- extract_envfit_scores(envfit.sand.adj, pval = 0.05)
)

## plot over the ordination 
(plot.envfit.sand <- plot_envfit(plot.mds.sand,
                                 envfit.scrs.sand,
                                 param.labels = param,
                                 label.col = "grey35")
)

## save plot
ggsave(here(figures.dir, "mds_envfit_sand.png"), 
       plot.envfit.sand,      
       width = 15, units = "cm", dpi = 300)
```

##### **Ordisurf - sand stations.**   
Since most environmental parameters don't vary linearly, especially in the marine environment, it's better to fit **surfaces** over the ordination (using a GAM) rather than vectors. There's a function for that in package vegan - ordisurf.  
First, get the environmental data we want (significant variables from envfit, p < 0.05).   
```{r ordisurf_data_sand}
(env.data.ordi.sand <- env.data.sand %>% 
   select(envfit.scrs.sand %>% pull(param))
)
```

Apply ordisurf sequentially to all these variables (keep results in a list).  
```{r ordisurf_sand_all}
## perform ordisurf on all variables in a loop
(ordi.list.all.sand <- apply(env.data.ordi.sand, MARGIN = 2, 
                             FUN = function(x) ordisurf(mds.sand ~ x, plot = FALSE))
)

## save this
write_rds(ordi.list.all.sand, 
          here(save.dir, "ordisurf_all_sand.RDS"))
```

Plot all ordisurfs in one go - with one monstrous mapply call, because I want plot titles, too. Not sure if I'll bother with renaming the ordisurf list so that the titles are more legible/suitable for direct use in the thesis text.  
```{r plot_ordisurf_sand_all}
mapply(function(x, y) {
    ## construct the file name 
    plot.name <- paste0("ordisurf_sand_", x, ".png")
    
    ## open png graphical device - we're working with base graphics
    png(here(figures.dir, plot.name), width = 1000, height = 1000, res = 200)
    
    ## plot ordisurf using my pretty custom function
    plot_mds_ordisurf(mds.sand, y)
    
    ## add a title
    title(main = x, col.main = "grey30", cex.main = 0.9, line = 0.5)
    
    ## close the graphics device
    dev.off()
}, 
names(ordi.list.all.sand), 
ordi.list.all.sand, 
SIMPLIFY = FALSE)

```

Plot all of the variables/ordisurfs on one big plot - very fiddly, lots of guesswork with base graphics! 
```{r plot_ordisurf_sand_all_composite}
## open png graphics device
png(here(figures.dir, "ordisurf_all_composite_sand"), width = 2000, height = 2000, res = 200)

## divide the plotting space - manually, knowing the number of subplots that will have to be fitted on one page
par(mfrow = c(3, 3))

## plot!
mapply(function(x, y) {
    ## plot ordisurf using my pretty custom function
    plot_mds_ordisurf(mds.sand, y)
    
    ## add a title
    title(main = x, col.main = "grey30", cex.main = 1, line = 0.5)
}, 
names(ordi.list.all.sand), 
ordi.list.all.sand, 
SIMPLIFY = FALSE)

## close the current graphics device, writing the file to disk
dev.off()

## return the plotting device settings to normal
par(mfrow = c(1, 1))
```

The observed MDS grouping is described 1) by the eutrophication/anthropogenic pressure gradient (water column parameters + LUSI), but also 2) by the sediment parameters - grain size & organic matter. That's why S5-Agalina is separate from the others - it has coarser sediments (more gravel) + organic matter because it's close to a natural reef, but it's in the outer bay - so less nutrients and more transparent water. That's why its community structure is also very distinct.  
This grouping should be confirmed through ANOSIM, and if deemed valid - SIMPER to see which the distinctive species are.  

##### **ANOSIM - sand stations.**   
This is a non-parametric permutation procedure applied to the rank (similarity) matrix underlying the ordination or classification of the samples.  
R statistic: -1 to 1; 1 = all replicates within sites are more similar to each other than to any other replicate from a different site; 0 = H0 is true (the same average similarities between and within sites). Usually 0 < R < 1 => some degree of difference observed between sites.  
Best course of analysis: 1) global ANOSIM - overall difference between groups; if significant - 2) where does the main between-group difference come from?  
=> examine R values for each pairwise comparison: large = complete separation, small - little or no difference.  
NB ANOSIM doesnâ€™t really have much statistical power and tends to get confounded by higher variances!..  

Let's try grouping by the apparent MDS clusters.  
```{r anosim_mds_clusters_sand}
anosim.kmeans.sand <- anosim(zoo.abnd.sand %>% 
                               select(-c(station:replicate)) %>%
                               mutate_all(sqrt),
                             grouping = kmeans.clusters.sand)

summary(anosim.kmeans.sand)

```
So the grouping is highly significant..  
Let's proceed with SIMPER to see which are the species contributing the most to this..   

##### **SIMPER - sand stations**   
This is another one of the confused-by-high variances distance-based methods
First - check the species contributions to the **between-group variance**.
```{r simper_between_group_sand}
# simper.sand <- simper(sqrt(num.zoo.abnd.sand), 
#                       group = factors.zoo.sand$stations)
# summary(simper.sand, ordered = TRUE)

```



#### Seagrass stations (Burgas Bay, 2013-2014)  
Import zoobenthic abundance data (cleaned and prepared).  