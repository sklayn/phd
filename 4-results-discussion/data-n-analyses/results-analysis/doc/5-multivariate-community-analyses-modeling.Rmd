---
title: "Multivariate analyses of community structure (modeling)"
date: "2019-01-28"
output: html_notebook
---

This notebook contains all multivariate analyses of zoobenthic community structure using the new, nearly unheard-of modeling methods: packages mvabund, boral.  
Again, to make it self-contained, there will be the same repetitive setup/data import/preparation part.  

***  

Setup!
```{r setup, include = FALSE}
library(knitr)

knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 2, .1, 2))  # smaller margin on top
})

## set the working directory to one up (all notebooks - kept in their own subdirectory within the project directory).
opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

## set knitr options for knitting code into the report.
opts_chunk$set(cache = TRUE, # save results so that code blocks aren't re-run unless code changes
               autodep = TRUE, # ..or unless a relevant earlier code block changed
               cache.comments = FALSE, # don't re-run if the only thing that changed was the comments
               highlight = TRUE, 
               small.mar = TRUE)
```

Define the working subdirectories.  
```{r workspace_setup}
## print the working directory, just to be on the safe side
paste("You are here: ", getwd())

data.dir <- "data"    ## input data files
functions.dir <- "R"  ## functions & scripts
save.dir <- "output"  ## clean data, output from models & more complex calculations
figures.dir <- "figs" ## plots & figures 
```

Import libraries.  
```{r import_packages, results = FALSE}
library(here) ## painless relative paths to subdurectories, etc.
library(tidyverse) ## data manipulation, cleaning, aggregation
library(viridis) ## smart & pretty colour schemes
library(mvabund) ## multivariate modeling analyses in ecology
library(boral) ## more multivariate modeling analyses in ecology
```

Organize some commonly-used ggplot2 modifications into a more convenient (and less repetitive) format. One day, I MUST figure out the proper way to set the theme..    
```{r custom_ggplot_settings_helpers}
## ggplot settings & things that I keep reusing
# ggplot_theme <- list(
#   theme_bw(),
#   theme(element_text(family = "Times"))
# )

## always use black-and-white theme
theme_set(theme_bw())

## helper to adjust ggplot text size & avoid repetitions 
text_size <- function(text.x = NULL,
                      text.y = NULL,
                      title.x = NULL,
                      title.y = NULL,
                      legend.text = NULL,
                      legend.title = NULL, 
                      strip.x = NULL, 
                      strip.y = NULL) {
  theme(axis.text.x = element_text(size = text.x),
        axis.text.y = element_text(size = text.y),
        axis.title.x = element_text(size = title.x),
        axis.title.y = element_text(size = title.y),
        legend.text = element_text(size = legend.text), 
        legend.title = element_text(size = legend.title), 
        strip.text.x = element_text(size = strip.x), 
        strip.text.y = element_text(size = strip.y)
        )
}

```

***  

#### **Sand stations (Burgas Bay, 2013-2014)**  
Import zoobenthic abundance data (cleaned and prepared).  
```{r import_zoo_abnd_sand}
zoo.abnd.sand <- read_csv(here(save.dir, "abnd_sand_orig_clean.csv"))

## convert station to factor (better safe than sorry later, when the stations are not plotted in the order I want them)
(zoo.abnd.sand <- zoo.abnd.sand %>% 
    mutate(station = factor(station, levels = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva")))
)
```

Remove the all-0 species (= not present in the current dataset).  
Maybe also remove the singletons (species appearing only once in the whole dataset and represented by a single individual = so rare that it's unlikely they carry important information, but it would probably improve the run times).  
```{r filter_zoo_data_sand}
(zoo.abnd.flt.sand <- zoo.abnd.sand %>%
   select(-c(station:replicate)) %>%
   select(which(colSums(.) > 0))
)
```


##### **LVM - model-based ordination**
Perform a model-based unconstrained ordination by fiting a pure latent variable model (package boral - Hui et al., 2014). This will allow to visualize the multivariate stations x species data - similar to nMDS, can be interpreted in the same way.   
I'm including a (fixed) row effect to account for differences in site total abundance - this way, the ordination is in terms of **species composition**.   
NB this takes about a million years to run! 
```{r lvm_sand}
lvm.sand <- boral(y = zoo.abnd.flt.sand, 
                  family = "negative.binomial",
                  
                  ## we want to control for site effects - there are 6 sites with 9 replicates each
                  row.eff = "fixed", row.ids = matrix(rep(1:6, each = 9), ncol = 1),  
                  ## 2 latent variables = 2 axes on which to represent the zoobenthic data
                  lv.control = list(num.lv = 2) 
                  
     #              ## example control structure, to check if function does what I want, because otherwise it takes an intolerably long time, and I'll shoot myself if I have to wait for it again
     #              mcmc.control = list(n.burnin = 10, n.iteration = 100,
     # n.thin = 1)
     #              
     
                  )

```

Check the summary and diagnostic plots for the LVM.  
```{r summary_lvm_sand}
summary(lvm.sand)

## model fit diagnostic plots
plot(lvm.sand) 
```
The residuals plots look fine (no patterns in the residuals vs fitted, so variance is homogeneous, the quantile plot shows a normal distribution of the residuals) - the model fits the data pretty well.  

Save the sand LVM.  
```{r save_lvm_sand}
write_rds(lvm.sand, 
          here(save.dir, "lvm_sand.RDS"))
```

Examine the biplot obtained by fitting the LVM, as well as the 20 most "important" species.   
```{r check_biplot_lvm_sand}
lvsplot(lvm.sand, jitter = T, biplot = TRUE, ind.spp = 20)
```

All in all, the final result resembles the nMDS ordination very much - same 4 clusters (Kraimorie + Chukalya, AKin, Agalina, Sozopol + Paraskeva). Kraimorie and Chukalya are better distinguished on the LVM plot than on the MDS, but still.  
The run time is extremely, extremely long (~1h), but the data don't need to be transformed, and the model fit can be examined and adjusted if necessary.    
The species singled out as significant are probably somewhat different - have to check!   

Redo the biplot, because this one is not very pretty. I'm not adding the species on top, first because I'm too lazy to figure out the procedure for ordering them, and second because the plot gets too busy.   
```{r extract_lvm_coord_sand}
## extract the LV coordinates of the stations from the model, so that the plot can be redone in ggplot 
lvs.coord.sand <- as_tibble(lvm.sand$lv.median)

## add the stations from the original zoobenthic table (order was not modified)
(lvs.coord.sand <- lvs.coord.sand %>% 
  bind_cols(zoo.abnd.sand %>% select(station))
)

```

Make the plot and save it.  
```{r plot_lvm_sand}
(plot.lvm.sand <- ggplot(lvs.coord.sand) + 
    geom_point(aes(x = lv1, y = lv2, colour = station)) + 
    scale_color_brewer(palette = "Set2", name = "station", 
                       labels = paste0("S", as.numeric((unique(lvs.coord.sand %>% pull(station)))))) +
   labs(x = "LV1", y = "LV2")
)

ggsave(file = here(figures.dir, "lvm_sand.png"), 
       plot.lvm.sand, 
       width = 15, units = "cm", dpi = 300)
```

##### **GLM fitting for abundance - environmental data**  
Let's fit GLMs to the sites x species matrix to try and explain the observed differences in community structure by the variation of the environmental parameters.  
These functions all come from package **mvabund**.  
Import the environmental data - the one cleaned, prepared and saved in the previous notebook (classical multivariate methods). It contains long-term averages for the water column data (2009-2011 + 2013-2014) at each station, repeated for each replicate, and the sediment data (2013-2014), again repeated to the same number of replicates. Only the variables determined to be significant by PCA are kept.       
```{r import_env_data_sand} 
env.sand <- read_csv(here(save.dir, "env_data_ordinations_sand.csv"))

## convert station to factor
(env.sand <- env.sand %>% 
    mutate(station = factor(station,
                            levels = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva")))
)
```
Station is a factor, the rest of the variables are numeric.  

Turn the zoobenthic data (minus the all-0 taxa) into a matrix - easier for the mvabund package and methods to deal with.  
```{r matrix_abnd_sand}
## there is already one subset of filtered count data (54 x 147) - use it 
zoo.mvabnd.sand <- mvabund(zoo.abnd.flt.sand)
```

###### **manyGLM by LVM clusters**
First, let's see if the groups from the latent variable model (more or less equal to the clusters from the classical ordination) are valid, and which species exhibit a response.  
```{r clusters_lvm_sand}
## construct the vector of the clusters by hand, it's easier that way.. 
lvm.clusters.sand <- c(rep(1, times = 18), rep(2:4, each = 9), rep(3, times = 9))

## convert to factor
(lvm.clusters.sand <- factor(lvm.clusters.sand))
```

Check the model assumptions. 
1. Mean-variance assumption => determines the choice of family parameter. Can be checked by plotting residuals vs fits: if little pattern - the chosen mean-variance assumption is plausible.  
Another way: direct plotting (variance ~ mean), for each species within each factor
level.  
```{r check_mean_variance_lvm_sand}
plot(manyglm(zoo.mvabnd.sand ~ lvm.clusters.sand, family = "negative.binomial"))

meanvar.plot(zoo.mvabnd.sand ~ lvm.clusters.sand, table = TRUE)
```

It's not perfect, but it's not too terrible either. 

2. Assumed relationship between mean abundance and environmental variables - link function and formula.
When quantitative variables are included in the model (for now, not relevant - will be in the next model) -> if there is a trend in size of residuals at different fitted values (e.g. U-shape,..) = violation of the log-linearity assumption.
  
Everything looks more or less fine; fit the model. 
```{r fit_glms_lvm_sand}
glms.lvm.sand <- manyglm(zoo.mvabnd.sand ~ lvm.clusters.sand, 
                         family = "negative.binomial")

```

Explore the fit (residuals, diagnostic plots, etc.).  
```{r explore_glms_lvm_sand}
## residuals vs fitted values
plot(glms.lvm.sand)

## all traditional lm diagnostic plots
plot.manyglm(glms.lvm.sand, which = 1:3)
```

I really don't like the rainbow palette, but I would like to include these plots in my thesis results.. Will have to do something about it, just not right now.  
Save the model!  
```{r save_glms_lvm_sand}
write_rds(glms.lvm.sand, 
          here(save.dir, "glms_lvm_sand.RDS"))
```

Let's see the model summary (NB takes a LOT of time if there are many resamplings!).  
```{r summary_glms_lvm_sand}
(glms.lvm.sand.summary <- summary(glms.lvm.sand, 
                                  test = "LR", p.uni = "adjusted",
                                  nBoot = 999, ## limit the number of permutations if you just want to check it out
                                  show.time = "all")
)
```

The factor (here - groups outlined by the LVM) is highly significant according to the models.  
This also allows us to see which species exhibit a response to the chosen factor. 
The LR (likelihood ratio) statistic is used as a measure of the strength of individual taxon contributions to the observed patterns. 
I'll save the summary for safekeeping, but I'll also run an anova - to get an analysis of deviance table on the model fit (also better for extracting the species contributions, or at least I know how to do it).  
```{r save_summary_glms_lvm_sand}
write_rds(glms.lvm.sand.summary, 
          here(save.dir, "glms_lvm_sand_summary.RDS"))
```

Run the anova on the model. 
```{r anova_glms_lvm_sand}
(glms.lvm.sand.aov <- anova.manyglm(glms.lvm.sand, 
                                    test = "LR", p.uni = "adjusted", 
                                    nBoot = 999, ## limit the number of permutations for a shorter run time   
                                    show.time = "all") 
)
```
I probably shouldn't have printed out all this, but oh well who cares.  

NOW let's get the taxa with the highest contributions to the tested pattern (here - clusters in the LVM, which are really the different soft-bottom habitats).  
```{r relative_taxon_contrib_glms_lvm_sand}
## retrieve and plot (top 10) species with the highest contribution to the patterns tested

## get 2nd row from table of univariate test stats (= change in deviance due to groups)
uniSorted <- sort(glms.lvm.sand.aov$uni.test[2, ], decreasing = TRUE, index.return = TRUE)

# get those species' names and plot them
dimnames(zoo.mvabnd.sand)[[2]][uniSorted$ix[1:10]]
plot(zoo.mvabnd.sand ~ lvm.clusters.sand, var.subset = uniSorted$ix[1:10])

# get the percentage of change in deviance due to this "top ten" => only about
# 28%, so cannot focus on just them if we want the whole story
sum(glms.lvm.sand.aov$uni.test[2, uniSorted$ix[1:10]]) / sum(glms.lvm.sand.aov$uni.test[2, ])

# with 50 species, most of the change in deviance is explained (76%). Unfortunately, this makes for a horrible, horrible plot.. 
sum(glms.lvm.sand.aov$uni.test[2, uniSorted$ix[1:50]]) / sum(glms.lvm.sand.aov$uni.test[2, ])

```

```{r}
sp_univar <- as_tibble(glms.lvm.sand.summary$uni.test, rownames = "species")
sp_p <- as_tibble(glms.lvm.sand.summary$uni.p, rownames = "species")

sp_all <- left_join(sp_univar, sp_p, by = "species")  

sp_all %>% 
  select(species, contains("Inter")) %>%
  arrange(`(Intercept).y`, desc(`(Intercept).x`))

sp_all %>% 
  select(species, contains("3")) %>%
  arrange(lvm.clusters.sand3.y, desc(lvm.clusters.sand3.x))
```



LR expresses how many times more likely the data are under one model than the other. This likelihood ratio, or equivalently its logarithm, can then be usedto compute a p-value, or compared to a critical value to decide whether to reject the null model in favour of the alternative model.