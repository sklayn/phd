---
title: "Environmental parameters - cleaning & preparation"
date: "2018-03-24"
output: 
  html_notebook:
    theme: paper
---
  
Setup!  
```{r setup, include = FALSE}
library(knitr)

knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 2, .1, 2))  # smaller margin on top
})

## set the working directory to one up (all notebooks - kept in their own subdirectory within the project directory).
opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

## set knitr options for knitting code into the report.
opts_chunk$set(cache = TRUE, # save results so that code blocks aren't re-run unless code changes
               autodep = TRUE, # ..or unless a relevant earlier code block changed
               cache.comments = FALSE, # don't re-run if the only thing that changed was the comments
               highlight = TRUE, 
               small.mar = TRUE)
```
Define the working subdirectories.  
```{r workspace_setup}
## print the working directory, just to be on the safe side
paste("You are here: ", getwd())

data.dir <- "data"    # input data files
functions.dir <- "R"  # functions & scripts
save.dir <- "output"  # clean data, output from models & more complex calculations
figures.dir <- "figs" # plots & figures 
```
Import libraries.  
```{r import_packages, results = FALSE}
library(here) # painless relative paths to subdurectories, etc.
#library(mice) # explore missing values 
library(tidyverse) # data manipulation, cleaning, aggregation
#library(sjPlot) # exporting publication-quality tables to .doc files, etc.
library(viridis) # smart & pretty colour schemes
```

Organize some commonly-used ggplot2 modifications into a more convenient (and less repetitive) format.  
```{r custom_ggplot_settings_helpers}
## ggplot settings & things that I keep reusing
# ggplot_theme <- list(
#   theme_bw(),
#   theme(element_text(family = "Times"))
# )

## always use black-and-white theme
theme_set(theme_bw())

## helper to adjust ggplot text size & avoid repetitions 
text_size <- function(text.x = NULL,
                      text.y = NULL,
                      title.x = NULL,
                      title.y = NULL,
                      legend.text = NULL,
                      legend.title = NULL, 
                      strip.x = NULL, 
                      strip.y = NULL) {
  theme(axis.text.x = element_text(size = text.x),
        axis.text.y = element_text(size = text.y),
        axis.title.x = element_text(size = title.x),
        axis.title.y = element_text(size = title.y),
        legend.text = element_text(size = legend.text), 
        legend.title = element_text(size = legend.title), 
        strip.text.x = element_text(size = strip.x), 
        strip.text.y = element_text(size = strip.y)
        )
}

```
***  
Environmental parameters that were measured in parallel with the zoobenthic sampling during the study (& other studies, which I might use if I decide it is possible):   
* water column nutrients, chl-a, suspended matter  
* water clarity (Secchi depth)  
* O2 concentrations (profiles every 1 m to the bottom) - but only occasionally, so just a momentary snapshot and shouldn't really be considered significant/meaningful.  
* sediment parameters - grain size & fraction proportions, total organic matter content (%), heavy metals (again only occasionally).   
Since (most) stations were selected because there were old monitoring stations at the same/nearby locations, there is fairly long-term data on nutrient concentrations, chl-a, suspended matter, water clarity at least. This is a good thing, because opportunistic samplings of these parameters, which vary strongly even daily, and very much so seasonally, cannot reveal the real patterns (e.g. higher eutrophication levels at some stations, such as those hypothesized here for the inner Burgas Bay stations).   
Therefore, the long-term data (averaged) will be used in the analyses wherever possible (and available), to try to determine the effects of this pressure on the macrobenthic communities.   

All of these datasets need to be cleaned and/or processed before use in the analyses.  
```{r import_environmental_data}
## water column parameters
(water.params <- read_csv(here(data.dir, "water_column_LT_all.csv"))
)

## seagrass parameters
(seagrass.params <- read_csv(here(data.dir, "zostera_raw_shoots_biomass.csv"))
)

## sediment parameters & heavy metals
(sediment.params <- read_csv(here(data.dir, "sediments.csv"))
)

## oxygen in water
(oxygen <- read_csv(here(data.dir, "oxygen_all.csv"))
)

```
  
Looks fine. Let's get cleaning, then!  
  
####  Data cleaning & processing  
##### Water column parameters  
To have more data for my stations, I'll add to them the data from some other nearby stations in Burgas Bay (and Sozopol Bay): Atia -> Akin; Maslen nos -> Paraskeva.
```{r water_params_cleaning}
water.params <- water.params %>% 
  mutate(station = recode(station, "Atia" = "Akin", "Maslen nos" = "Paraskeva"))
```

Check the missing data in the water column parameters.    
```{r missing_data_water_column_1}
### check the distribution of NAs in the water column parameters
## first, for the whole dataset (long-term, as it may be)
as_tibble(mice::md.pattern(water.params))
```
Display them more visually.  
```{r missing_data_water_column_2, results = FALSE, fig.show = "asis"}
## a more visual way of displaying the same NAs (package VIM)
VIM::aggr(water.params, 
          col = c("blue", "red"),
          numbers = TRUE,
          sortVars = TRUE,
          labels = names(water.params),
          cex.axis = 0.7, gap = 3)

```
There are some; mostly for the Secchi depth, which wasn't systematically measured.   

We'll do the same for the missing values only during the study period (2012-2014).
```{r missing_data_water_column_study, results = FALSE, fig.show = "asis"}
water.params %>%
  filter(year == 2012 | year == 2013 | year == 2014) %>%
  VIM::aggr(col = c("blue", "red"),
          numbers = TRUE,
          sortVars = TRUE,
          labels = names(water.params),
          cex.axis = 0.7, gap = 3)

```
Looks like the Secchi depth is the major offender here, too, but all other water column parameters are complete.   

Now, summarise the water column data.  
First - by station, month and year (= mean of all depths at each station and point of time).
```{r summary_water_column_st_yr_mo}
## average values by station, year and month (-> over the different depths)
(water.params.summary <- water.params %>%
  group_by(station, year, month) %>%
  select(-c(year:depth)) %>%
  summarise_all(funs(mean), na.rm = TRUE)
)

```
OK, we'll save this dataset - in case non-summarized data is needed for some analysis of variance etc. (yes it turns out it is needed, found out the hard way).     
```{r save_water_column_raw_clean}
write_csv(water.params.summary, 
          here(save.dir, "water_column_raw_clean.csv"))
```

Then, summarise by station -> get **long-term averages** over the whole period of data availability (such as it is), and also sd, min and max values. This will then be exported as a table, formatted from within R (hopefully), to be included in the relevant thesis appendix.
```{r summary_water_column_st_long-term}
water.params.summary.st.LT <- water.params.summary %>%
  group_by(station) %>%
  select(-c(year, month)) %>%
  summarise_all(funs(mean, sd, min, max), na.rm = TRUE) %>%
  # round all numbers to the 2nd decimal place
  mutate_if(is.numeric, round, 2) %>%
  # reorder columns (clumsily)
   select(station,
          starts_with("Ntot"),
          starts_with("Ninorg"),
          starts_with("NH4"),
          starts_with("NO3"),
          starts_with("PO4"),
          starts_with("chl_a"),
          starts_with("seston"),
          starts_with("secchi")
          )

## reorder by station - custom order (sand, seagrass, 2012)
(water.params.summary.st.LT <- water.params.summary.st.LT %>%
  mutate(station = factor(station, levels = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva",
                                              "Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo",
                                              "Konski", "Ribka"))) %>% 
  arrange(station)
)  

```
NB For Vromos, there are no Secchi depths, so it's impossible to calculate summary statistics (NaN, Inf, -Inf..).  

Now let's play with the **oxygen data**.  
The oxygen dataset contains measures of O2 concentrations (mg/L) & saturations (%) in the water column, usually every 1 m from the surface to the bottom, at different stations. This is a complete dataset with all stations ever measured (would be useful for a visualization on a map grid with extrapolated values etc., especially for Sozopol Bay where there were many measures/stations - I might even play with it a little later, for the fun of it). However, for the multivariate analyses I'm only going to keep the data from my stations, and summarize it as the rest of the water column parameters.  
```{r filter_oxygen}
## get only the stations I'm interested in
(oxygen.summary <- oxygen %>% 
   filter(station %in% c("Konski1", "Konski2", "Ribka2", "Gradina2", "Kraimorie", "Chukalya", "Akin", "Sozopol", "Paraskeva", "Agalina", "Poda3", "Gradina1", "Ropotamo1", "Ropotamo2", "Otmanli1", "Otmanli2", "Poda1", "Poda2"))
)
```

Check the NAs.  
```{r missing_data_oxygen, results = FALSE, fig.show = "asis"}
oxygen.summary %>%
  VIM::aggr(col = c("blue", "red"),
          numbers = TRUE,
          sortVars = TRUE,
          labels = names(oxygen.summary),
          cex.axis = 0.7, gap = 3)
```
Most of the oxygen saturations are missing (naturally, they were not recorded at the time - because it's possible to calculate them from the oxygen concentration, the water temperature and techincally, the depth - if my stations weren't so shallow).   
I don't think I'll bother with calculations, though - I'll just use the concentrations.  
There are also some missing values in the temperature - I'll just omit those.   

NB These were measured **without correction for seawater** - which it turns out is necessary, but I didn't know at the time. For future reference, READ THE INSTRUMENT'S MANUAL BEFORE DOING ANYTHING NEXT TIME. However, all the values contain the same error - so I'm going to let it slide.. I don't trust the oxygen data anyway, it's only a series of snapshots without decent replication to account for variability, so it's next to useless.        

We'll first get the oxygen concentrations in the bottom layer of the water column - might be more informative for the community composition, even though they are merely snapshots at single points in time..  
```{r bottom_oxygen_st}
(oxygen.bottom <- oxygen.summary %>%
   select(station:O2, temperature, depth) %>%
   group_by(station, day, month, year) %>%
   ## the bottom oxygen is the value of O2 at the maximum depth at each station/sampling 
   filter(depth == max(depth)) %>% 
   rename(O2_bottom = O2, temperature_bottom = temperature)
 )
```

Now average the oxygen over the different depths by sampling date & station.  
```{r average_oxygen_st}
(oxygen.summary.st <- oxygen.summary %>%
  select(station:O2, temperature) %>%
  group_by(station, day, month, year) %>%
  summarize(O2_mean = mean(O2), 
            temperature_mean = mean(temperature))
 )
```

Add the bottom O2 (& temperature) to the summary dataset by station.  
```{r average_bottom_oxygen_st_merged}
(oxygen.summary.st.all <- left_join(oxygen.summary.st, 
                                    oxygen.bottom %>% select(-c(habitat, depth)), 
                                    by = c("station", "day", "month", "year"))
 
 )
```
Save this, too - before summarizing further.   
```{r save_oxygen_raw_clean}
write_csv(oxygen.summary.st.all, 
          here(save.dir, "oxygen_raw_clean.csv"))
```

Now, average for the stations only (all data available, if you can call it long-term) - as for the other water column variables.  
```{r summary_oxygen_st_long-term}
## fix the station names first, to match my data & the water column parameters before
oxygen.summary.st.all <- oxygen.summary.st.all %>%
  ungroup() %>%
  mutate(station = str_extract(station, "[^\\d]+"))

## summarize everything by station as before - mean, sd, min & max
oxygen.summary.st.LT <- oxygen.summary.st.all %>% 
  group_by(station) %>% 
  select(-c(station:year)) %>%
  summarize_all(funs(mean, sd, min, max), na.rm = TRUE)

## add a row for Vromos, where O2 was not measured at all, but I need it to merge with the other water column data
oxygen.summary.st.LT <- oxygen.summary.st.LT %>% 
  add_row(station = "Vromos")

## remove double _mean from column names & rearrange
names(oxygen.summary.st.LT) <- gsub("_mean", "", x = names(oxygen.summary.st.LT))

(oxygen.summary.st.LT <- oxygen.summary.st.LT %>% 
    mutate(station = factor(station, levels = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva",
                                                "Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo",
                                                "Konski", "Ribka"))) %>% 
    arrange(station) %>% 
    # rearrange columns
    select(station, 
           O2, O2_sd, O2_min, O2_max, 
           starts_with("O2_b"),
           temperature, temperature_sd, temperature_min, temperature_max, 
           starts_with("temperature_b"))
)
```

Add the oxygen to the water column summary. 
```{r add_O2_water_summary}
(water.params.summary.st.LT <- left_join(water.params.summary.st.LT, oxygen.summary.st.LT, by = "station")
)
```

Unfortunately, I'll transcribe these summaries by hand in the appendix (no time to figure out better ways), which means endless hassle if anything at all changes at some point..   

Save the summary (mean values only) to use directly in the multivariate analyses (avoid repeating all this cleaning). No splitting/rearranging for now.   
```{r save_water_column_summary_LT}
write_csv(water.params.summary.st.LT %>% select(station, contains("mean"), O2, O2_bottom, temperature, temperature_bottom), 
          here(save.dir, "water_column_summary_LT.csv"))
```

##### Seagrass parameters  
These are shoot counts for all seagrass species at the study sites, above-ground wet biomass (leaves), and below-ground biomass (roots & rhizomes). They could be important for the zoobenthic communities - e.g. denser seagrass meadows might provide more refuges against predation, etc.  
These are the raw counts / weights, which will be extrapolated to shoots.m^-2^ and g.m^-2^ by multiplying by 779/10000 (= corer area for seagrass samples).   
```{r seagrass_params_cleaning}
### fix the station names
(seagrass.params <- seagrass.params %>% 
  ## separate the horrifying sample ID for 2013 into its component parts (station + replicate) and keep only the station
  separate(sampleID, into = "station", sep = "_", extra = "drop") %>% 
  ## remove the whitespace in the middle of the 2012 samples to be consistent with the zoobenthic datasets 
  mutate(station = gsub(pattern = " ", replacement = "", x = station)) %>% 
  ## recode the 2014 station names (in their raw form, they contain a reference to the GPS point - to distinguish them from the 2013 stations)
  mutate(station = recode(station, "Gradina083" = "Gradina1", "Gradina084" = "Gradina2"))
)
```

The raw files for the seagrass parameters were a mess - tons of sheets, copy-pasted subsets everywhere, missing samples without reason given, data filters, cryptic colours and graphs... The result is that in some samples, the shoot counts and the biomasses for the different seagrass species do not match/were missing. The extent of this was especially ridiculous in the 2013 dataset.     
To deal with that, several assumptions were made:  
* shoot count is primary: if there is no shoot count for a seagrass species for a particular sample/replicate, but there are biomass values, first I checked if other replicates from the same station had the reverse problem (shoot count with no biomass); if yes, it was assumed that the replicate number for the biomass was entered wrong and it was moved to the "bare" shoot count.  
Yes, no one could be sure that this is good practice, but I needed a strategy in order to move on. If somehow the truth is found, I'll be sure to correct the values. I kept a file with the unfixed inconsistencies highlighted, so I can go back relatively easily.  
If there were no "orphan" shoot counts in the replicates, the biomass values were ignored (replaced with 0).  
* if a biomass value was 0 in the raw data, it was replaced with 0.01 - the analytical limit of the scale (no such thing as 0 g weight).   
* where one of the biomasses (above- or below-ground) was missing, it was replaced with 0.01 again.   
* all other missing values were replaced with 0 - it was assumed they were simply not entered during the data processing.   

Check for missing values anyway, just in case.   
```{r missing_data_seagrass, results = FALSE, fig.show = "asis"}
## a more visual way of displaying the same NAs (package VIM)
VIM::aggr(seagrass.params, 
          col = c("blue", "red"),
          numbers = TRUE,
          sortVars = TRUE,
          labels = names(seagrass.params),
          cex.axis = 0.7, gap = 3)

```
Yay! After all the possibly-deal-breaking manipulations, there really is no missing data here.  

Now summarise the seagrass parameters.  
With the exception of 2012, there are zoobenthic samples from only 1 station/meadow (number 1 everywhere). Don't know which way of summarising them is correct.. on one hand, no - better to have multiple sites in each meadow to better reflect variability in cover, biomass, etc. - more representative of that particular meadow's characteristics.. On the other hand, my animals - not so mobile - don't exactly care what the cover is at other points in the meadow, so maybe the snapshot closest to their own location will explain the observed zoobenthic community differences better. Actually, they could care - the species that eat the seagrass, if any; or if they eat particular epiphytes which differ between seagrass species... But that's an experiment for another day.     

Bottom line: In general, I'm keeping all stations from 2012, and the st.1's from the other years. Just in case, however, I'll also keep the raw (cleaned) file with all stations etc. - it might be useful for the elastic net/PCA crappity crap.   
I'm interested in the shoot density and biomass of **all seagrass species** at each station/site, taken together (again, the animals don't particularly care).   
```{r summary_seagrass_filter_st}
## first, filter out the st.2's at each sampling location for 2013 & 2014  
seagrass.params.summary <- seagrass.params %>% 
  filter(year %in% c(2013, 2014), grepl("1", x = station))

## then add the data for 2012 (from the original tibble)
(seagrass.params.summary <- bind_rows(seagrass.params.summary,
                                      seagrass.params %>% filter(year == 2012))
)
```

First, calculate the total shoot count, above- and below-ground biomass - keeping **all stations and replicates**, and save.  
```{r seagrass_all_species_all_samples}
(seagrass.params.all.stations <- seagrass.params %>%
  group_by(station, year, replicate) %>%
  ## clumsy, but works, and I don't expect to have to do it again anyway - except below
  transmute(shoot_count = znol_sd_count + zmar_sd_count + zpal_sd_count + pp_sd_count, 
            ag_biomass_wet = znol_ag_wet + zmar_ag_wet + zpal_ag_wet + pp_ag_wet, 
            bg_biomass_wet = znol_bg_wet + zmar_bg_wet + zpal_bg_wet + pp_bg_wet)
)

write_csv(seagrass.params.all.stations, 
          here(save.dir, "seagrass_all_stations.csv"))
```

Then do the same on the reduced dataset, and proceed with the other summaries.   
```{r summary_seagrass_all_species}
(seagrass.params.summary.all <- seagrass.params.summary %>%
  group_by(station, year, replicate) %>%
  ## clumsy, but works, and I don't expect to have to do it again anyway
  transmute(shoot_count = znol_sd_count + zmar_sd_count + zpal_sd_count + pp_sd_count, 
            ag_biomass_wet = znol_ag_wet + zmar_ag_wet + zpal_ag_wet + pp_ag_wet, 
            bg_biomass_wet = znol_bg_wet + zmar_bg_wet + zpal_bg_wet + pp_bg_wet)
)
```
Average by station & year (2013-2014), and by site (2012) - 2 separate tibbles.  
```{r summary_seagrass_2013_2014}
## mean, sd, min, max
seagrass.params.summary.2013.2014 <- seagrass.params.summary.all %>% 
  filter(year %in% c(2013, 2014)) %>%
  group_by(station, year) %>% 
  select(-c(station:replicate)) %>%
  summarise_all(funs(mean, sd, min, max), na.rm = TRUE)

## recalculate - per m2
seagrass.params.summary.2013.2014 <- seagrass.params.summary.2013.2014 %>% 
    group_by(station, year) %>%
    select(-c(station, year)) %>% 
    mutate_all(funs(. / 779 * 10000)) 

## fix station names & rearrange a little (looks better)
(seagrass.params.summary.2013.2014 <- seagrass.params.summary.2013.2014 %>% 
    ungroup() %>%
    mutate(station = gsub("1", "", x = station)) %>%
    mutate(station = factor(station, levels = c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo"))) %>% 
    arrange(station, year) %>% 
    select(station, year, contains("shoot"), contains("ag"), contains("bg"))
)
```
Save (only the means per m2) for use in the multivariate analyses.  
```{r save_seagrass_summary_2013_2014}
write_csv(seagrass.params.summary.2013.2014 %>% select(station, year, contains("mean")), 
          here(save.dir, "seagrass_summary_2013_2014.csv"))
```

Now repeat for the 2012 data, which needs to be aggregated by site this time.  
```{r summary_seagrass_2012}
## get the sites
seagrass.params.summary.2012 <- seagrass.params.summary.all %>% 
  filter(year %in% c(2012)) %>%
  # match 0+ characters at the beginning of the given string which are not digits - because the names of the stations here consist of site + station number.
  mutate(site = str_extract(station, "[^\\d]+")) %>%
  mutate(site = factor(site, levels = c("Konski", "Ribka", "Gradina"))) %>%
  select(site, station, year, replicate, everything())

## mean, sd, min, max
seagrass.params.summary.2012 <- seagrass.params.summary.2012 %>%
  group_by(site) %>% 
  select(-c(site:replicate)) %>%
  summarise_all(funs(mean, sd, min, max), na.rm = TRUE)

## recalculate - per m2
(seagrass.params.summary.2012 <- seagrass.params.summary.2012 %>% 
    group_by(site) %>%
    select(-site) %>% 
    mutate_all(funs(. / 779 * 10000)) %>% 
    # rearrange a little
    select(site, contains("shoot"), contains("ag"), contains("bg"))
)

```
Save this, too (again, means per m2 only). 
```{r save_seagrass_summary_2012}
write_csv(seagrass.params.summary.2012 %>% select(site, contains("mean")), 
          here(save.dir, "seagrass_summary_2012.csv"))
```

##### Sediment parameters  
These were measured only during the study period; some of them are derived mathematically (sorting coefficient, mean grain size..).  
Check out the missing values.  
```{r missing_data_sediments, results = FALSE, fig.show = "asis"}
VIM::aggr(sediment.params, 
          col = c("blue", "red"),
          numbers = TRUE,
          sortVars = TRUE,
          labels = names(sediment.params),
          cex.axis = 0.7, gap = 3)
```
As expected, there are lots and lots of them:  
* the heavy metals were measured only once at every site, and only in 2013-2014 - they are missing everywhere else.  
* some sediment samples were damaged, and sometimes not taken at all at several of the sand stations in Burgas Bay (+ 1 in Sozopol Bay); however, there is always at least one value/station, so it would be possible to impute the missings - in this case, through a variant of **mean value imputation** - the missing values will be replaced by the average of available values for that station. While it is possible to use a more sophisticated method (I initially read up on MCMC and tried it with package mice & friends), I don't see much difference, so I'd rather stick with the simpler solution. The drawback is that this reduces any correlation that might exist in the dataset - so it reduces the effectiveness of multivariate analyses later (that's why I didn't use regular mean value imputation, which averages the whole dataset).   

Summarize the sediment parameters - by station and year for sand/seagrass; by site & habitat for 2012. OK I'm not convinced this is meaningful - these are only point measures; what sort of summary is that?  
```{r summary_sediments_sand}
(sediment.params.summary.sand <- sediment.params %>% 
   filter(year %in% c(2013, 2014), habitat == "S") %>%
   mutate(station = factor(station, levels = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva"))) %>% 
   group_by(station, year) %>% 
   select(-c(station:habitat)) %>%
   summarise_all(funs(mean, sd, min, max), na.rm = TRUE) %>%
   arrange(year, station)
)
```

Summarize the **st.1** data from all meadows. As with the seagrass parameters, I originally decided it was more useful to look at the immediate environment of my macrozoobenthic communities.   
```{r summary_sediments_seagrass}
(sediment.params.summary.seagrass <- sediment.params %>% 
   ## filter the seagrass st.1's from 2013 and 2014 
   filter(year %in% c(2013, 2014), habitat == "Z", grepl("1", x = station)) %>%
   ## remove the numbers from the station names
   mutate(station = gsub(pattern = "1", replacement = "", x = station)) %>%
   ## make station a factor
   mutate(station = factor(station, levels = c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo"))) %>% 
   group_by(station, year) %>% 
   select(-c(station:habitat)) %>%
   summarise_all(funs(mean, sd, min, max), na.rm = TRUE) %>%
   arrange(year, station)
)

```

Now clean a little the whole dataset of sediments in seagrass (2013-2014). Save without summarizing, preserving variability.    
```{r save_sediments_seagrass_all_stations}
(sediment.params.all.st.seagrass <- sediment.params %>% 
   ## filter all seagrass stations from 2013 and 2014 
   filter(year %in% c(2013, 2014), habitat == "Z") %>%
   ## remove the numbers from the station names
   mutate(station = str_extract(station, "[^\\d]+")) %>%
   ## make station a factor
   mutate(station = factor(station, levels = c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo"))) %>% 
   arrange(station, year)
)

write_csv(sediment.params.all.st.seagrass, 
          here(save.dir, "sediments_seagrass_raw_clean.csv"))
```


```{r summary_sediments_2012}
## get the sites, again
sediment.params.summary.2012 <- sediment.params %>% 
  filter(year == 2012) %>%
  # match 0+ characters at the beginning of the given string which are not digits - because the names of the stations here consist of site + station number.
  mutate(site = str_extract(station, "[^\\d]+")) %>%
  mutate(site = factor(site, levels = c("Konski", "Ribka", "Gradina"))) %>%
  select(site, station, year, habitat, everything(), -c(month, Cu:Ni))

## mean, sd, min, max
sediment.params.summary.2012 <- sediment.params.summary.2012 %>%
  group_by(site, habitat) %>% 
  select(-c(site:habitat)) %>%
  summarise_all(funs(mean, sd, min, max), na.rm = TRUE)

## rearrange a little
(sediment.params.summary.2012 <- sediment.params.summary.2012 %>% 
    arrange(habitat, site) %>% 
    select(site, habitat, contains("TOM"), contains("grain"), contains("sort"), contains("gravel"), contains("sand"), contains("silt"), contains("moisture"))
) 
```

Impute the missing values in the dataset, as described above.  
Exception: the heavy metals, which are single measurements - they will just be repeated for each station however many times needed.  
```{r impute_missing_sediments_sand}
## replace missing values with the average for the station
sediment.params.imputed.sand <- sediment.params %>% 
  filter(year %in% c(2013, 2014), habitat == "S") %>%
  mutate(station = factor(station, levels = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva"))) %>%
  group_by(station) %>%
  mutate_at(vars(TOM:silt_clay), function(x) replace(x, is.na(x), mean(x, na.rm = TRUE)))

## for the heavy metals, just repeat each measured value (there's only 1 per station)
(sediment.params.imputed.sand <- sediment.params.imputed.sand %>% 
    group_by(station) %>%
    fill(Cu:Ni, .direction = "down")
)

## save for safekeeping / use in multivariate analyses
write_csv(sediment.params.imputed.sand, 
          here(save.dir, "sediments_imputed_sand.csv"))
```

Now do the same for the seagrasses (2013-2014), which is considerably easier - we only need to fill in the heavy metals (this time, upwards).   
```{r impute_missing_sediments_seagrass}
(sediment.params.imputed.seagrass <- sediment.params %>% 
   filter(year %in% c(2013, 2014), habitat == "Z", grepl("1", x = station)) %>% 
   ## remove the numbers from the station names
   mutate(station = str_extract(station, "[^\\d]+")) %>%
   ## make station a factor
   mutate(station = factor(station, levels = c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo"))) %>% 
   group_by(station) %>% 
   fill(Cu:Ni, .direction = "up")
)

## save 
write_csv(sediment.params.imputed.seagrass, 
          here(save.dir, "sediments_imputed_seagrass.csv"))
```

For the 2012 data, the only missing values are for station K1, in TOM and moisture content (that sample got overturned on the boat). Since the analyses for this dataset are at the site level, this is irrelevant; we'll just save the site-level summary, minus the heavy metals (not measured then), and be done with it.     
```{r save_sediments_2012}
## we only want the variable means. Calling this dataset "imputed" so that I know it goes with the other two.    
sediment.params.imputed.2012 <- sediment.params.summary.2012 %>% 
  select(site, habitat, ends_with("mean"))

## rename the variables, and print out the tibble to make sure evverything is as expected 
names(sediment.params.imputed.2012) <- names(sediment.params.imputed.2012) %>% 
  str_replace(pattern = "_mean", replacement = "")

sediment.params.imputed.2012

## save
write_csv(sediment.params.imputed.2012, 
          here(save.dir, "sediments_imputed_2012.csv"))
```

##### LUSI  
The Land Use Simplified Index (Flo et al. 2011) is an index of anthropogenic pressure according to coastal land use. The calculation is simple, but requires land cover data according to type of land use (Corine Land Cover, in this case - CLC2012), and various corrections.  
The other significant pressures considered in the modified verison of LUSI (Romero, 2011) are rivers/point sources, harbours and tourism, adjacent water bodies in bad/moderate state or under high anthropogenic pressure.  
A correction for the shape of the coastline is also applied: this factor influences water residency times and thus the amount of pressure exerted on coastal ecosystems.  

Import the data - land use areas by watersheds.  
NB HAVE TO OPEN THE WATERSHED SPATIAL DATABASE SOMEHOW, TO DETERMINE WHICH PARTICULAR ONES WERE USED - FOR NOW, I ONLY HAVE THE PDF MAPS FROM THE 2014 PHYTOBENTHOS INTERCALIBRATION.   
```{r import_land_use_data}
## land use areas (in the watersheds we are interested in, according to CLC2012) 
(land.use <- read_csv(here(data.dir, "lusi_land_use_watersheds.csv")))

## corrections for the LUSI calculation 
(lusi.corrections <- read_csv(here(data.dir, "lusi_corrections_watersheds.csv")))

```
Calculate the LUSI scores for each watershed (using a custom function, in case I need to repeat the calculations somewhere). LUSI itself will be explicitly calculated, because the function gets too complex and black-boxy.  
```{r calculate_lusi_scores}
## import custom function
source(here(functions.dir, "lusi_scores.R"))

## calculate the scores
(lusi.scores.watersheds <- lusi_scores(land.use))

```

Good. Now calculate LUSI for our watersheds, applying all necessary corrections.  
```{r calculate_lusi}
lusi.scores.watersheds <- left_join(lusi.scores.watersheds, 
                               lusi.corrections %>% select(-notes_correction), # the notes are not needed for calculations 
                               by = "watershed")

(lusi.watershed <- lusi.scores.watersheds %>% 
    mutate(LUSI = rowSums(select(., -c(watershed, coast_correction))) * coast_correction) %>% 
    select(watershed, LUSI)
)
```
Now let's match the stations to the corresponding watersheds. Again, have to find those and put them on a map in M&M.    
```{r lusi_watersheds_stations}
## get the stations from the water parameter summary tibble
lusi.st <- water.params.summary.st.LT %>% select(station)

## assign the watersheds - again, from the phytobenthos IC - 2014
(lusi.st <- lusi.st %>% 
    mutate(watershed = case_when(station %in% c("Konski", "Sozopol", "Agalina") ~ "Agalina_Sozopol", 
                                 station %in% c("Akin", "Chukalya", "Vromos") ~ "Atia", 
                                 station %in% c("Poda", "Otmanli", "Kraimorie") ~ "Burgas_Poda_Kraimorie_Otmanli", 
                                 station %in% c("Ribka", "Gradina") ~ "Gradina", 
                                 station == "Ropotamo" ~ "Ropotamo_Vatahori", 
                                 station == "Paraskeva" ~ "MaslenNos_SvParaskeva"))
)

## add the LUSI values & save
(lusi.st <- left_join(lusi.st,
                      lusi.watershed, 
                      by = "watershed")
)

write_csv(lusi.st, here(save.dir, "lusi_st.csv"))
```

