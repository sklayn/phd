---
title: "Environmental parameters - analysis & variable selection"
date: "2018-04-10"
output: 
  html_notebook:
    theme: paper
---
  
Setup!  
```{r setup, include = FALSE}
library(knitr)

knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 2, .1, 2))  # smaller margin on top
})

## set the working directory to one up (all notebooks - kept in their own subdirectory within the project directory).
opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

## set knitr options for knitting code into the report.
opts_chunk$set(cache = TRUE, # save results so that code blocks aren't re-run unless code changes
               autodep = TRUE, # ..or unless a relevant earlier code block changed
               cache.comments = FALSE, # don't re-run if the only thing that changed was the comments
               highlight = TRUE, 
               small.mar = TRUE)
```

Define the working subdirectories.  
```{r workspace_setup}
## print the working directory, just to be on the safe side
paste("You are here: ", getwd())

data.dir <- "data"    # input data files
functions.dir <- "R"  # functions & scripts
save.dir <- "output"  # clean data, output from models & more complex calculations
figures.dir <- "figs" # plots & figures 
```

Import libraries.  
```{r import_packages, results = FALSE}
library(here) # painless relative paths to subdurectories, etc.
library(tidyverse) # data manipulation, cleaning, aggregation
library(viridis) # smart & pretty colour schemes
library(caret) # variable selection, pruning & other wrapper functions for modeling

library(FactoMineR) # PCA
library(factoextra) # visualization & exploration of PCA results

# if not installed:
# devtools::install_github("kassambara/factoextra")
# install.packages("FactoMineR", "factoextra")

library(glmnet) # elastic net variable selection & model fitting 
```

Organize some commonly-used ggplot2 modifications into a more convenient (and less repetitive) format.  
```{r custom_ggplot_settings_helpers}
## ggplot settings & things that I keep reusing
# ggplot_theme <- list(
#   theme_bw(),
#   theme(element_text(family = "Times"))
# )

## always use black-and-white theme
theme_set(theme_bw())

## helper to adjust ggplot text size & avoid repetitions 
text_size <- function(text.x = NULL,
                      text.y = NULL,
                      title.x = NULL,
                      title.y = NULL,
                      legend.text = NULL,
                      legend.title = NULL, 
                      strip.x = NULL, 
                      strip.y = NULL) {
  theme(axis.text.x = element_text(size = text.x),
        axis.text.y = element_text(size = text.y),
        axis.title.x = element_text(size = title.x),
        axis.title.y = element_text(size = title.y),
        legend.text = element_text(size = legend.text), 
        legend.title = element_text(size = legend.title), 
        strip.text.x = element_text(size = strip.x), 
        strip.text.y = element_text(size = strip.y)
        )
}

```

***  

This notebook details the analyses & variable selection of the environmental parameters. I'm giving them their own notebook for clarity and simplicity.  
This is a direct continuation of the cleanup & summarization notebook on environmental parameters; I'm going to import some of the summary tibbles produced there directly from the save folder.    
Again, the analyses will proceed in 3 separate datasets: 2012, sand (2013-2014), and seagrass (2013-2014).   
Two lines of analysis will be applied:  
1) PCA - to see which variables best account for the differences between stations. The "winners" will go on to the multivariate analyses attempting to relate community structure to environment.  
PCA will be applied on 3 sets of explanatory variables - water column (+ LUSI), sediments (+ seagrass, where relevant), and heavy metals; y = station (and habitat, in the case of sand). Prior to the PCA, some (feeble) variable selection will be performed - mostly to get rid of highly correlated variables.  
2) Elastic net - another method of variable selection.  
Again, there will be 3 sets of explanatory variables - as above.  
y = categorical (station, habitats) - logistic regression with multinomial models & grouped lasso penalty.  
y = numeric (species abundances) - multi-response Gaussian linear regression with many correlated responses (+ maybe should be applied over a sparse matrix).  

##### Sand stations (Burgas Bay, 2013-2014)  
Import environmental data.   
```{r import_water_data_sand}
## contains the long-term water column parameters, summarized by station. 
water <- read_csv(here(save.dir, "water_column_summary_LT.csv"))

## filter (manually) to get only the sand 2013-2014 stations
(water.sand <- water %>% 
    filter(station %in% c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva"))
)
```

Import the sediment data (it also contains the heavy metals).   
```{r import_sediment_data_sand}
sediments <- read_csv(here(save.dir, "sediments_imputed_sand.csv"))

## split into sediment parameters sesnu stricto, and heavy metals
(sediments.sand <- sediments %>% 
    select(station:year, TOM:silt_clay)
)  

(heavy.metals.sand <- sediments %>% 
    select(station:year, Cu:Ni) 
)
```

Import LUSI and add it to the water column data, although strictly speaking, it isn't really..  
```{r import_lusi_sand}
(lusi <- read_csv(here(save.dir, "lusi_st.csv"))
)

## we'll match them by station - and we only want the sand stations - the rows of x (the water column data) where there are matching values in y (LUSI) -> e.g. inner join 
(water.sand <- inner_join(water.sand, 
                          lusi %>% select(-watershed), 
                          by = "station")
)
```
The nutrients all decrease towards the outer bay, more or less so, and so do the chl-a and suspended matter; the transparency (Secchi depth) increases - this is the long-term (anthropgenic) eutrophication gradient in Burgas Bay, consistent with previous studies (..) & models.   

Now let's check the correlations between water column parameters. More or less important: LUSI is (significantly) positively correlated with most long-term nutrient concentrations, chl-a and suspended matter, and negatively correlated with Secchi depth, which is good - shows that it's a good indicator of the anthropogenic pressure gradient of Burgas Bay. Could maybe be used as a proxy for all of these in the analyses? As a side note, the fact that it doesn't require the analyses of samples upon water samples is also not too shabby.     
```{r water_sand_correlations}
Hmisc::rcorr(as.matrix(water.sand %>% select(-station)), 
             type = "pearson")
```
  
Now we'll proceed with the variable selection for the PCA. For whatever it's worth, I don't think PCA with so few observations can be valid, but hey, all the kids are doing it.    
We'll just eliminate the most inter-correlated variables using package caret.  
```{r filter_correlated_sand}
# calculate the correlation matrix (on the numeric variables only)
water.sand.cors <- cor(water.sand %>% select(-station))
  
# find and eliminate the highly correlated variables. NB names = FALSE, to return column index
highly.cor.water.sand <- findCorrelation(water.sand.cors, cutoff = 0.85)

water.sand.red <- water.sand %>% 
  select(-station) %>% # otherwise column indices don't match 
  select(-highly.cor.water.sand)


water.sand.pca <- prcomp(water.sand.red, center = TRUE, scale. = TRUE) 

# check the results
summary(water.sand.pca)
biplot(water.sand.pca)
```

Unfortunately, this eliminates LUSI, which as we saw is highly correlated with all nutrients, etc. - and I'd like to keep it, to check against macrozoobenthic community structure.  
However, for the sake of not throwing away hard work, I will go through the motions of visualizing and exploring the PCA results. Procedure uses packages FactoMineR and factoextra.  
```{r pca_water_sand}
# scale and center the data (different units), and add back the stations 
water.sand.red.scaled <- scale(water.sand.red, center = TRUE, scale = TRUE)
water.sand.red.scaled <- bind_cols(water.sand %>% select(station), 
                                   as.tibble(water.sand.red.scaled))

## perform PCA with FactoMineR - it's equivalent to the base version, anyway, but the visualization expects a particular structure of the results, so easier to do it this way. 
water.sand.pca.fin <- PCA(water.sand.red.scaled,
                          scale.unit = FALSE, 
                          quali.sup = 1, 
                          graph = TRUE)

```
Good enough.. for some reason doesn't show colours nor visualize the results as before - maybe some functions masked? or don't work with this version of ggplot? or other incompatibility, e.g. with rmarkdown/knitr/..?   Will try updating first, and see then.. 
```{r explore_pca_water_sand_1}
# 1. Check the variances of the principal components. Amount of variation retained by each PC = eigenvalue. First PC = direction with maximum amount of variation in the dataset.
water.sand.pca.fin$eig

# 2. Visualize the importance of the PCs (-> scree plot)
fviz_screeplot(water.sand.pca.fin)

# 3. Plot correlations/loadings of the variables with the PCs = variable loadings. Variables can be plotted as points in the component space using their loadings as coordinates.

# look at variable coordinates
water.sand.pca.fin$var$coord

# visualize the variables on the factor map. Correlation circle can help visualize the most correlated variables (variables that group together). 
fviz_pca_var(water.sand.pca.fin)

# 4. Explore the quality of the representation for variables on the factor map 
# (cos2 = squared loadings for variables = cor * cor = coord * coord). The closer a variable to the circle of correlations, the better its representation on the factor map, and the more important it is to interpret these components. If a variable is perfectly represented by only 2 components, the sum of the cos2 = 1, and the variables will be positioned on the circle of correlations. For some variables - more than 2 components required to perfectly represent the data; then - variables positioned inside circle of correlations. Variables close to the center of the plot - less important for the first components.

# rearrange the data frame successively by PC axes so that it's easier to read and find the variables most correlated with each axis (custom function)
pca_repres_quality(pca.res = pca.result, choice = "var", param = "cos2")

# plot the variables factor map, and color the vectors according to the amount of correlation to the PCs. Can select the minimum value of cos2 and the PC axes to plot.
# PC1-PC2
fviz_pca_var(water.sand.pca.fin, axes = c(1, 2), select.var = list(cos2 = 0.5)) + 
  scale_color_gradient2(low = "skyblue", mid = "navyblue", high = "red", midpoint = 0.7) +
  theme_minimal()

# PC1-PC3    
fviz_pca_var(pca.result, axes = c(1, 3), select.var = list(cos2 = 0.5)) + 
  scale_color_gradient2(low = "skyblue", mid = "navyblue", high = "red", midpoint = 0.7) +
  theme_minimal()

```

