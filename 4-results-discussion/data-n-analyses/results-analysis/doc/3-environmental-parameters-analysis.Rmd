---
title: "Environmental parameters - analysis & variable selection"
date: "2018-04-30"
output: 
  html_notebook:
    theme: paper
---
  
Setup!  
```{r setup, include = FALSE}
library(knitr)

knit_hooks$set(small.mar = function(before, options, envir) {
    if (before) par(mar = c(2, 2, .1, 2))  # smaller margin on top
})

## set the working directory to one up (all notebooks - kept in their own subdirectory within the project directory).
opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

## set knitr options for knitting code into the report.
opts_chunk$set(cache = TRUE, # save results so that code blocks aren't re-run unless code changes
               autodep = TRUE, # ..or unless a relevant earlier code block changed
               cache.comments = FALSE, # don't re-run if the only thing that changed was the comments
               highlight = TRUE, 
               small.mar = TRUE)
```

Define the working subdirectories.  
```{r workspace_setup}
## print the working directory, just to be on the safe side
paste("You are here: ", getwd())

data.dir <- "data"    # input data files
functions.dir <- "R"  # functions & scripts
save.dir <- "output"  # clean data, output from models & more complex calculations
figures.dir <- "figs" # plots & figures 
```

Import libraries.  
```{r import_packages, results = FALSE}
library(here) # painless relative paths to subdurectories, etc.
library(tidyverse) # data manipulation, cleaning, aggregation
library(viridis) # smart & pretty colour schemes
library(caret) # variable selection, pruning & other wrapper functions for modeling

library(FactoMineR) # PCA
library(factoextra) # visualization & exploration of PCA results
library(FactoInvestigate) # automatic report, visualization & interpretation of PCA results (analyses done with FactoMineR)

# if not installed:
# devtools::install_github("kassambara/factoextra")
# install.packages("FactoMineR", "factoextra")

library(glmnet) # elastic net variable selection & model fitting 
```

Organize some commonly-used ggplot2 modifications into a more convenient (and less repetitive) format.  
```{r custom_ggplot_settings_helpers}
## ggplot settings & things that I keep reusing
# ggplot_theme <- list(
#   theme_bw(),
#   theme(element_text(family = "Times"))
# )

## always use black-and-white theme
theme_set(theme_bw())

## helper to adjust ggplot text size & avoid repetitions 
text_size <- function(text.x = NULL,
                      text.y = NULL,
                      title.x = NULL,
                      title.y = NULL,
                      legend.text = NULL,
                      legend.title = NULL, 
                      strip.x = NULL, 
                      strip.y = NULL) {
  theme(axis.text.x = element_text(size = text.x),
        axis.text.y = element_text(size = text.y),
        axis.title.x = element_text(size = title.x),
        axis.title.y = element_text(size = title.y),
        legend.text = element_text(size = legend.text), 
        legend.title = element_text(size = legend.title), 
        strip.text.x = element_text(size = strip.x), 
        strip.text.y = element_text(size = strip.y)
        )
}

```

***  

This notebook details the analyses & variable selection of the environmental parameters. I'm giving them their own notebook for clarity and simplicity.  
This is a direct continuation of the cleanup & summarization notebook on environmental parameters; I'm going to import some of the summary tibbles produced there directly from the save folder.    
Again, the analyses will proceed in 3 separate datasets: 2012, sand (2013-2014), and seagrass (2013-2014).   
Two lines of analysis will be applied:  
1) PCA - to see which variables best account for the differences between stations. The "winners" will go on to the multivariate analyses attempting to relate community structure to environment.  
PCA will be applied on 3 sets of explanatory variables - water column (+ LUSI), sediments (+ seagrass, where relevant), and heavy metals; y = station (and habitat, in the case of sand). Prior to the PCA, some (feeble) variable selection will be performed - mostly to get rid of highly correlated variables.  
2) Elastic net - another method of variable selection.  
Again, there will be 3 sets of explanatory variables - as above.  
y = categorical (station, habitats) - logistic regression with multinomial models & grouped lasso penalty.  
y = numeric (species abundances) - multi-response Gaussian linear regression with many correlated responses (+ maybe should be applied over a sparse matrix).  

##### Sand stations (Burgas Bay, 2013-2014)  
Import environmental data.   
```{r import_water_data_sand}
## contains the long-term water column parameters, summarized by station. 
water <- read_csv(here(save.dir, "water_column_summary_LT.csv"))

## filter (manually) to get only the sand 2013-2014 stations
(water.sand <- water %>% 
    filter(station %in% c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva"))
)
```

Import the sediment data (it also contains the heavy metals).   
```{r import_sediment_data_sand}
sediments <- read_csv(here(save.dir, "sediments_imputed_sand.csv"))

## split into sediment parameters sesnu stricto, and heavy metals
(sediments.sand <- sediments %>% 
    select(station:year, TOM:silt_clay)
)  

(heavy.metals.sand <- sediments %>% 
    select(station:year, Cu:Ni) 
)
```

Import LUSI and add it to the water column data, although strictly speaking, it isn't really..  
```{r import_lusi_sand}
(lusi <- read_csv(here(save.dir, "lusi_st.csv"))
)

## we'll match them by station - and we only want the sand stations - the rows of x (the water column data) where there are matching values in y (LUSI) -> e.g. inner join 
(water.sand <- inner_join(water.sand, 
                          lusi %>% select(-watershed), 
                          by = "station")
)
```
The nutrients all decrease towards the outer bay, more or less so, and so do the chl-a and suspended matter; the transparency (Secchi depth) increases - this is the long-term (anthropgenic) eutrophication gradient in Burgas Bay, consistent with previous studies (..) & models.   

Now let's check the correlations between water column parameters. More or less important: LUSI is (significantly) positively correlated with most long-term nutrient concentrations, chl-a and suspended matter, and negatively correlated with Secchi depth, which is good - shows that it's a good indicator of the anthropogenic pressure gradient of Burgas Bay. Could maybe be used as a proxy for all of these in the analyses? As a side note, the fact that it doesn't require the analyses of samples upon water samples is also not too shabby.     
```{r water_sand_correlations}
Hmisc::rcorr(as.matrix(water.sand %>% select(-station)), 
             type = "pearson")
```
  
Now we'll proceed with the variable selection for the PCA. For whatever it's worth, I don't think PCA with so few observations can be valid, but hey, all the kids are doing it.    
We'll just eliminate the most inter-correlated variables using package caret.  
```{r filter_correlated_sand}
# calculate the correlation matrix (on the numeric variables only)
water.sand.cors <- cor(water.sand %>% select(-station))
  
# find and eliminate the highly correlated variables. NB names = FALSE, to return column index
highly.cor.water.sand <- findCorrelation(water.sand.cors, cutoff = 0.85)

water.sand.red <- water.sand %>% 
  select(-station) %>% # otherwise column indices don't match 
  select(-highly.cor.water.sand)


water.sand.pca <- prcomp(water.sand.red, center = TRUE, scale. = TRUE) 

# check the results
summary(water.sand.pca)
biplot(water.sand.pca)
```

Unfortunately, this eliminates LUSI, which as we saw is highly correlated with all nutrients, etc. - and I'd like to keep it, to check against macrozoobenthic community structure.  
However, for the sake of not throwing away hard work, I will go through the motions of visualizing and exploring the PCA results. Procedure uses packages FactoMineR and factoextra.  
```{r pca_water_sand}
# scale and center the data (different units), and add back the stations 
water.sand.red.scaled <- scale(water.sand.red, center = TRUE, scale = TRUE)
water.sand.red.scaled <- bind_cols(water.sand %>% select(station), 
                                   as.tibble(water.sand.red.scaled))

## perform PCA with FactoMineR - it's equivalent to the base version, anyway, but the visualization expects a particular structure of the results, so easier to do it this way. 
water.sand.pca.fin <- PCA(water.sand.red.scaled,
                          scale.unit = FALSE, 
                          quali.sup = 1, 
                          graph = FALSE)

## display the summary and biplot
summary(water.sand.pca.fin)

(plot.water.sand.pca <- fviz_pca_biplot(water.sand.pca.fin, axes = c(1, 2), 
                                        label = c("var", "ind"), 
                                        col.var = "cos2", gradient.cols = c("skyblue", "navyblue", "red"), 
                                        repel = TRUE)
)

ggsave(here(figures.dir, "pca_water_sand.png"), plot.water.sand.pca, dpi = 300)
```
The first 2 PCs explain ~73% of the total variance - not too bad.. Add the third, and the proportion of the explained variance becomes nearly 90%.  
Stations 2 and 6, then 1 and 4 contribute the most to the first PC (Dim.1), nad are best represented on it (cos2). Stations 1, 4, 2 and 3 contribute the most to PC2, and are again best represented on it (see also the supplementary categories table).   
On a plot of PC1-2, the separation is between stations 1 2 in one end (to the left), and stations 4 and 6 in the other (right); stations 3 and 5 are close  together near the middle (not too well represented).    
In terms of variables, PC1 can be considered a representation of the eutrophication gradient - highly correlated with Ntotal and chl-a on one side ("pulling" to the left), and with bottom O2 (and total O2) on the other ("pulling" to the right). PC2 represents mainly the temperature ("pulls" down), and to a lesser degree - NO3.  

Since I did these, I found out about a new package doing **automatic** exploration & report on the PCA - FactoInvestigate. Let's try it out, see what we get..   
This inevitably fails, because it can't describe the dimensions with no actual variation - I'm commenting it out, but leaving it here for the sake of completeness.   
```{r report_pca_water_sand}
# Investigate(water.sand.pca.fin, file = "pca_report_water_sand.Rmd", document = "html_document", remove.temp = TRUE)
```

To reiterate - the automatic report **fails** at the attempt to describe the dimensions - that's because there is nothing to describe; the orignal data only has 1 value per station - not really appropriate for PCA, which attempts to describe variability after all (what variability with only 1 value?).  
Before that, it manages to say that the analysis should not be attempted at all - see generated report. Quoting: "An estimation of the right number of axes to interpret suggests to not interpret the analysis at all.  Indeed, the amount of inertia of the first axis is not higher than that obtained by the 0.95-quantile of random distributions (46.6% against 61.68%). This observation suggests that no axis is carrying a real information."

**Also, I don't like how LUSI got excluded - I think in the end, I might just show the correlation table to demonstrate that LUSI reflects well the eutrophication gradient, then just pass it on to the community structure analyses. Will dramatically reduce the number of variables + the uncertainty associated with only a few discrete samples of highly variable parameters such as nutrients and oxygen.**  

In any case, let's save the PCA result - just in case, to avoid repeating a million times later.   
```{r save_pca_water_sand}
write_rds(water.sand.pca.fin, path = here(save.dir, "pca_water_sand.RDS"))
```


Now do a proper PCA on non-summarized water column data (essentially a repeat of Mitko's PhD analyses, but ok).
```{r import_water_non_summarized_all}
## import water column raw - non-summarized - data. 
water.all <- read_csv(here(save.dir, "water_column_raw_clean.csv"))

## get only the sand stations from the water column dataset
(water.sand.all <- water.all %>% 
   filter(station %in% c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva")) %>% 
   ungroup() %>%
   mutate(station = factor(station, levels = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva")))
)
```

Reduce the dataset a little, removing correlations.   
```{r filter_correlated_water_sand}
# calculate the correlation matrix (on the numeric variables only)
water.sand.all.cors <- cor(water.sand.all %>% select(-c(station:month)))
  
# find and eliminate the highly correlated variables. NB names = FALSE, to return column index
highly.cor.water.sand.all <- findCorrelation(water.sand.all.cors, cutoff = 0.85)

(water.sand.all.red <- water.sand.all %>% 
    select(-c(station:month)) %>% # otherwise column indices don't match 
    select(-highly.cor.water.sand.all)
)
```

```{r pca_water_sand_all_red}
## scale and center the reduced dataset
water.sand.all.red.scaled <- scale(water.sand.all.red,
                                   center = TRUE, scale = TRUE)

water.sand.all.red.scaled <- bind_cols(water.sand.all %>% select(station),
                                       as.tibble(water.sand.all.red.scaled))

## convert stations into factor, because for some stations there are more observations than for others, which causes the Investigate function to freak out later
water.sand.all.red.scaled <- water.sand.all.red.scaled %>% 
  mutate(station = factor(station, levels = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva")))


## perform the PCA
water.sand.all.red.pca <- PCA(water.sand.all.red.scaled, scale.unit = FALSE, quali.sup = 1)

Investigate(water.sand.all.red.pca, 
            file = "pca_water_sand_all_red_report.Rmd", document = "html_document", 
            out.selec = TRUE,
            remove.temp = TRUE)  
```

Goody! At least the analysis is significant - although the elimination threshold of correlation is probably too high - judging from how close the vectors of the N species are situated...   

```{r save_pca_water_sand_all_red}
write_rds(water.sand.all.red.pca, 
          here(save.dir, "pca_water_sand_all_red.RDS"))
```


***  
###### **Sidebar: PCA result exploration - demonstrated on water parameters on sand stations, 2013-14**   
PCA done like this is meaningless.  
However, let's explore the results a bit - just to demonstrate the basic procedure with PCA quality checks & interpretation.   
1) Check the variances of the principal components. Amount of variation retained by each PC = eigenvalue. First PC = direction with maximum amount of variation in the dataset.  
```{r explore_pca_water_sand_1}
water.sand.pca.fin$eig
```
2) Visualize the importance of the PCs (-> scree plot).   
```{r explore_pca_water_sand_2}
fviz_screeplot(water.sand.pca.fin)
```
3) Plot correlations/loadings of the variables with the PCs = variable loadings. Variables can be plotted as points in the component space using their loadings as coordinates.  
```{r explore_pca_water_sand_3}
## look at variable coordinates on each PC
water.sand.pca.fin$var$coord

## visualize the variables on the factor map. Correlation circle can help visualize the most correlated variables (variables that group together). 
fviz_pca_var(water.sand.pca.fin, col.circle = "grey")
```

4) Explore the quality of the representation for variables on the factor map (cos2 = squared loadings for variables = cor x cor = coord x coord). The closer a variable to the circle of correlations, the better its representation on the factor map, and the more important it is to interpret these components. If a variable is perfectly represented by only 2 components, the sum of the cos2 = 1, and the variables will be positioned on the circle of correlations. For some variables - more than 2 components required to perfectly represent the data; then - variables positioned inside circle of correlations. Variables close to the center of the plot - less important for the first components.  
```{r explore_pca_water_sand_4}
## check the variables with highest correlation to the first few PCs
as_tibble(water.sand.pca.fin$var$cos2, rownames = "var") %>%
  arrange(desc(Dim.1))

## plot the variables factor map, and color the vectors according to the amount of correlation to the PCs. Can select the minimum value of cos2 and the PC axes to plot.
# PC1-PC2
fviz_pca_var(water.sand.pca.fin, axes = c(1, 2), select.var = list(cos2 = 0.5), 
             col.var = "cos2", gradient.cols = c("skyblue", "navyblue", "red"))

# PC1-PC3
fviz_pca_var(water.sand.pca.fin, axes = c(1, 3), select.var = list(cos2 = 0.5), 
             col.var = "cos2", gradient.cols = c("skyblue", "navyblue", "red"))

```

5) Check the contributions of the variables to the PCs. Variables that are correlated with PC1 and PC2 - the most important in explaining the variability in the dataset.  
Variables not correlated with any PC or correlated with the last dimensions - low contribution; could be removed to simplify overall analysis.  
% contribution of a variable in accounting for the variability in a given PC = (variable.cos2 x 100) / (total cos2 of component)  
```{r explore_pca_water_sand_5}
as_tibble(water.sand.pca.fin$var$contrib, rownames = "var") %>%
  arrange(desc(Dim.1))
```

6) Visualize the most important variables associated with a given PC. The red line on the graph represents the expected average contribution (if all variable contributions were uniform). For a given component, any variable with contribution larger than that cutoff could be considered important.  
```{r explore_pca_water_sand_6}
plot_pca_var_contrib <- function(pca.res, choice = c("var", "ind"), axes = c(start : end)) {
  ## helper for plotting variable/individuals contributions (as bars) to the specified PC axes. 
  ## Dependencies: factoextra
  
  # plot contributions for each axis separately
  for(i in axes){
    print(fviz_contrib(pca.res, choice = choice, axes = i))
  }
  
  # plot the overall contributions to the specified axes
  print(fviz_contrib(pca.res, choice = choice, axes = axes))
}



# variable contributions on PC1, PC2 and PC3 (+ all 3 axes together)
plot_pca_var_contrib(water.sand.pca.fin, 
                     choice = "var", 
                     axes = c(1:3))


# if there are many variables in the dataset, we can show only the top n contributing variables:
fviz_contrib(water.sand.pca.fin, choice = "var", axes = 1, top = 5)

```

7) Color variables on the variable factor map according to their contributions - highlights the most important variables in explaining the variations retained  by the PCs.
```{r explore_pca_water_sand_7}
fviz_pca_var(water.sand.pca.fin, col.var = "contrib") 

## variable contributions to PC1-2
fviz_pca_var(water.sand.pca.fin, axes = c(1, 2), col.var = "contrib") 
##..and to PC1-3
fviz_pca_var(water.sand.pca.fin, axes = c(1, 3), col.var = "contrib")

```

8) Dimension description - identify the most correlated variables with a given PC -> but only works with more categories (e.g. replicates at the stations, years,..). I'm including it as a reminder that it exists as an option.    
```{r explore_pca_water_sand_8}
# dimdesc(water.sand.pca.fin, axes = c(1:5))
```

9) Explore individuals (= stations/species/..) in the same way as the variables just now.  
```{r explore_pca_water_sand_9}
## coordinates of individuals on the PCs
water.sand.pca.fin$ind$coord

## plot & label by station (can also colour by group - year,..)
fviz_pca_ind(water.sand.pca.fin, label = c("quali", "ind"))

## quality of representation for individuals on the PCs (cos2)
as_tibble(water.sand.pca.fin$ind$cos2, rownames = "ind") %>% 
  arrange(desc(Dim.1))

## correlation of individuals with PC1-2
fviz_pca_ind(water.sand.pca.fin, axes = c(1, 2), col.ind = "cos2", gradient.cols = c("skyblue", "navyblue", "red")) 

## ...and with PC1-3
fviz_pca_ind(water.sand.pca.fin, axes = c(1, 3), col.ind = "cos2", gradient.cols = c("skyblue", "navyblue", "red")) 

## contribution of individuals to the PCs
as_tibble(water.sand.pca.fin$ind$contrib, rownames = "ind") %>% 
  arrange(desc(Dim.1))

## visualize the most contributing individuals (stations) associated with a given PC
# PC1-3 + all 3 together (custom function)
plot_pca_var_contrib(water.sand.pca.fin, 
                     choice = "ind", 
                     axes = c(1:3))

## top 3 individuals (stations) contributing to PC1 (for ex.)
fviz_contrib(water.sand.pca.fin, choice = "ind", axes = 1, top = 3)

## individuals (stations) map colored according to their contribution
fviz_pca_ind(water.sand.pca.fin, col.ind = "contrib")

```
Sidebar end.  

***  

Let's try again with the **sediment parameters** - there are more values per station here, so should turn out better.  
```{r pca_sediments_sand}
# scale and center the data (different units), and add back the stations 
sediments.sand.scaled <- scale(sediments.sand %>% select(-c(station:year)), center = TRUE, scale = TRUE)
sediments.sand.scaled <- bind_cols(sediments.sand %>% select(station), 
                                   as.tibble(sediments.sand.scaled))

sediments.sand.pca <- PCA(sediments.sand.scaled, scale.unit = FALSE, quali.sup = 1)

Investigate(sediments.sand.pca, file = "pca_sediments_sand_report.Rmd", document = "html_document", remove.temp = TRUE)
```

*NB The knitting of the report fails if I try to put it in a subfolder of the working directory, so I'll just move it by hand afterwards - it will live in the output directory.*   

To summarize the report: the first two PCs capture a significant proportion of the variability of the dataset. The first PC is major - the estimation of the right number of axis to interpret suggests to restrict the analysis to the description of the first 1 axis.   
The dimension 1 opposes individuals such as 2, 1, 14, 13, 15 and 3 (Kraimorie and Agalina - to the right of the graph, characterized by a strongly positive coordinate on the axis) to individuals such as 7, 9 and 8 (Akin - to the left of the graph, characterized by a strongly negative coordinate on the axis).  
The group of individuals 2, 14, 13 and 15 (mostly Agalina) has:  
• high values for the variables gravel, moisture_content, mean_grain_size and sorting (strongest to weakest).  
• low values for the variable sand.  
The group of individuals 1 and 3 (Kraimorie) has:  
• high values for the variables silt_clay, TOM and sorting (strongest to weakest).  
The group of individuals 7, 9 and 8 (Akin) has:  
• high values for the variable sand.  
• low values for the variables mean_grain_size, sorting, gravel, TOM and moisture_content (weakest to strongest).  
**The variables mean_grain_size, sorting, sand and Sozopol are highly correlated with this dimension (respective correlation of 0.93, 0.96, 0.93, 0.91). These variables could therefore summarize themselves the dimension 1.**   
All in all, the PCA describes well the differences in sediment composition between stations. The stations form **4 main clusters**:    
- cluster 1 is made of individuals such as 7, 8 and 9 (Akin), with high values for the variable sand, and low values for the variables TOM, moisture_content, sorting, mean_grain_size and gravel (weakest to strongest).  
- cluster 2 is made of individuals such as 16 and 18 (Paraskeva), with high values for the variable moisture_content.  
- cluster 3 is made of individuals such as 2, 13, 14 and 15 (Agalina), with high values for the variables gravel, mean_grain_size and sorting (strongest to weakest), and low values for the variable sand.   
- cluster 4 is made of individuals such as 1 and 3 (Kraimorie), with high values for the variables silt_clay, TOM and sorting (strongest to weakest).  
Kraimorie and Agalina are similar in their sediment chracteristics (larger mean grain size, gravel & organic matter content), which could possibly explain similarities in their macrozoobenthic community structure.  
Same for Akin, (Sozopol) and Paraskeva - smaller grain size, predominantly sand.  
Chukalya is in the middle, but closer to the sandy stations.  

Save the sediment PCA, too, for posterity... 
```{r save_pca_sediments_sand}
write_rds(sediments.sand.pca, 
          here(save.dir, "pca_sediments_sand.RDS"))
```

Now do it one more time, but first remove the most correlated variables from the sediment dataset.   
```{r filter_correlated_sediments_sand}
## calculate the correlation matrix (on the numeric variables only)
sediments.sand.cors <- cor(sediments.sand %>% select(-c(station:year)))
  
## find and eliminate the highly correlated variables. NB names = FALSE, to return column index
highly.cor.sediments.sand <- findCorrelation(sediments.sand.cors, cutoff = 0.85)

(sediments.sand.red <- sediments.sand %>% 
    select(-c(station:year)) %>% # otherwise column indices don't match 
    select(-highly.cor.sediments.sand)
)
```

```{r pca_sediments_sand_red}
# scale and center the data (different units), and add back the stations 
sediments.sand.red.scaled <- scale(sediments.sand.red,
                                   center = TRUE, scale = TRUE)

sediments.sand.red.scaled <- bind_cols(sediments.sand %>% select(station),
                                       as.tibble(sediments.sand.red.scaled))

sediments.sand.red.pca <- PCA(sediments.sand.red.scaled, scale.unit = FALSE, quali.sup = 1)

Investigate(sediments.sand.red.pca, 
            file = "pca_sediments_sand_red_report.Rmd", document = "html_document",
            out.selec = FALSE, # don't check for outliers; it breaks the analysis
            remove.temp = TRUE)
```

OK, with the reduced sediment dataset, the PCA turns out not significant at all. Because it wasn't confusing enough to begin with...  

I'll save it anyway.   
```{r save_pca_sediments_sand_red}
write_rds(sediments.sand.red.pca, 
          here(save.dir, "pca_sediments_sand_red.RDS"))
```



For the **heavy metals**, I think the wisest would be to calculate the total (new variable, sum of all heavy metals), calculate another variable - ratio of every metal to Fe, which is usually present naturally in the environment, and to keep only Pb and Cd - source - pollution from human activities.    

**There are no national standards for environmental quality for heavy metals in sediments - these values are next to useless then. All I can say is at which station the concentration of Pb is higher, and some such.**   


###### **Elastic net - sand stations, 2013-14**  
First, let's throw all parameters together and do stations as a dependent variable. This means the water column parameters will have to be repeated 3 times, and merged with the sediments & heavy metals.   

```{r elastic_net_env_data_preparation_sand}
envir.en.sand <- left_join(sediments,
                           water.sand,
                           by = "station") 

## make station a factor
(envir.en.sand <- envir.en.sand %>% 
    mutate(station = factor(station, levels = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva")))
)
```

Despite everything I said before about substituting LUSI for all water column variables, I'm going to throw everything at the model and see how it does.   
First try: y = station   
It doesn't work, because there are too few observtions per group, this being the summarized long-term water column data (commented out to allow knitting of the notebook).    
```{r elastic_net_stations_sand}
# en.st.sand <- glmnet(x = as.matrix(envir.en.sand %>% select(TOM:LUSI)), 
#                      y = envir.en.sand %>% pull(station), 
#                      family = "multinomial", type.multinomial = "grouped")
# 
# plot(en.st.sand, xvar = "lambda", label = TRUE, type.coef = "2norm")
# 
# 
# cvfit.st.sand <- cv.glmnet(x = as.matrix(envir.en.sand %>% select(TOM:LUSI)), 
#                            y = envir.en.sand %>% pull(station), 
#                            family="multinomial", type.multinomial = "grouped")
# 
# plot(cvfit.st.sand)

```
So, glmnet fails because there are too few observations...   
I'll try again with non-summarized data - for the water, this will essentially repeat Mitko's PhD analyses, but what the hell, I have the computing power and I don't care...   
The raw data come from the enivronmental data cleaning notebook; I'll save them later to avoid repeating these steps, which I just did off the record..   
Starting with water column crap.  
```{r en_water_sand}
## starting with the non-summarized water column data (imported several chunks above, because needed for trying PCA). 
## remove row Paraskeva-2015 (the only one where seston is NaN) + variable secchi - has lots of NAs and NaNs which are not handled by glmnet
(water.sand.sub <- water.sand %>% 
    filter(!(station == "Paraskeva" & year == 2015)) %>% 
    select(-secchi)
)

## perform the elastic net shit
en.water.st.sand <- glmnet(x = as.matrix(water.sand.sub %>% select(chl_a:seston)), 
                           y = water.sand.sub %>% pull(station), 
                           family = "multinomial", type.multinomial = "grouped")

plot(en.water.st.sand, xvar = "lambda", label = TRUE, type.coef = "2norm")


cvfit.water.st.sand <- cv.glmnet(x = as.matrix(water.sand.sub %>% select(chl_a:seston)),
                                 y = water.sand.sub %>% pull(station), 
                                 family="multinomial", type.multinomial = "grouped")

plot(cvfit.water.st.sand)
```

All right, this is markedly better - no yelling, no complaints..   
Let's see which variables are the most important according to the elastic net.  
```{r coef_en_water_sand}
coef(en.water.st.sand, s = cvfit.water.st.sand$lambda.min)
```
Seston and NO3 are the (apparent) winners. All right, I'll try those..     
```{r test_glm_en_water_sand}
summary(glm(as.numeric(station) ~ NO3 + seston, data = water.sand.sub))
```
OK - the deviance drops between the null model and the actual model, although I couldn't say how significant this is.  
For now, let's pretend this is meaningful, and try again with the **sediment parameters minus the heavy metals**.    
```{r en_sediments_sand}
en.sediments.st.sand <- glmnet(x = as.matrix(sediments.sand %>% select(TOM:silt_clay)), 
                               y = sediments.sand %>% pull(station),
                               family = "multinomial", type.multinomial = "grouped")

plot(en.sediments.st.sand, xvar = "lambda", label = TRUE, type.coef = "2norm")


cvfit.sediments.st.sand <- cv.glmnet(x = as.matrix(sediments.sand %>% select(TOM:silt_clay)),
                                     y = sediments.sand %>% pull(station), 
                                     family="multinomial", type.multinomial = "grouped")

plot(cvfit.sediments.st.sand)
```

Multiple issues: <8 observations per class - doubtful validity of the results; no convergence for lambda after 100000 iterations; solutions for larger lambdas returned (?).  
However, the algorithm does return something - let's check it out...  It thinks 4 variables best explain the variability between stations.  
```{r coef_en_sediments_sand}
coef(en.sediments.st.sand, s = cvfit.sediments.st.sand$lambda.min)
```
```{r test_glm_en_sediments_sand}
summary(glm(as.numeric(as.factor(station)) ~ TOM + moisture_content + gravel + silt_clay, data = sediments.sand))
```
Well, despite all reservations, I'm going to try and see how well these do in envfit etc. to explain the variability of the macrozoobenthic communities themselves.      


Finally, I'll try with **habitats** as the dependent variable. Essentially, these are the groups that also come from the cluster analysis of community composition - so maybe it's more accurate to say they are the biotopes.   
This is only relevant for the sand communities (2013-2014) - the seagrasses are all one habitat/biotope, and 2012 are not so distinct (and the data are shitty).       
Whatever. I'm defining them by hand, then joining them to each dataset (water and sediments), and redoing the analyses.  
```{r import_habitats_sand}
## define the habitats (biotopes) = clusters from the MDS and other community structure analyses
(habitats.sand <- tibble(station = c("Kraimorie", "Chukalya", "Akin", "Sozopol", "Agalina", "Paraskeva"),
                         habitat = c(1, 1, 2, 3, 4, 3))
 )
```

Now perform the elastic net analysis using the non-summarized water column data (first adding the habitats to the dataset).  
```{r en_water_hab_sand}
## add habitats to water column (non-summarized) dataset
(water.sand.sub.hab <- left_join(water.sand.sub, 
                                 habitats.sand, 
                                 by = "station")
)

## make habitat a factor
water.sand.sub.hab <- water.sand.sub.hab %>% 
  mutate(habitat = factor(habitat))

## perform the elastic net with habitat as dependent variable
en.water.hab.sand <- glmnet(x = as.matrix(water.sand.sub.hab %>% select(chl_a:seston)), 
                            y = water.sand.sub.hab %>% pull(habitat), 
                            family = "multinomial", type.multinomial = "grouped")

plot(en.water.hab.sand, xvar = "lambda", label = TRUE, type.coef = "2norm")


cvfit.water.hab.sand <- cv.glmnet(x = as.matrix(water.sand.sub.hab %>% select(chl_a:seston)),
                                  y = water.sand.sub.hab %>% pull(habitat), 
                                  family="multinomial", type.multinomial = "grouped")

plot(cvfit.water.hab.sand)
```

Wow, no complaints here - what's going on?!  
```{r coef_en_water_hab_sand}
coef(en.water.hab.sand, s = cvfit.water.hab.sand$lambda.min)
```
Hm, NO3 and seston again. Great!   
Let's check out what the model says.    
```{r test_glm_en_water_hab_sand}
summary(glm(as.numeric(as.factor(habitat)) ~ NO3 + seston, data = water.sand.sub.hab))
```

Now, fingers crossed for the sediments.  
```{r en_sediments_hab_sand}
## add the habitats to the sediment dataset 
sediments.sand.hab <- left_join(sediments.sand, 
                                habitats.sand, 
                                by = "station")

## convert habitat to factor
sediments.sand.hab <- sediments.sand.hab %>% 
  mutate(habitat = factor(habitat))

en.sediments.hab.sand <- glmnet(x = as.matrix(sediments.sand.hab %>%
                                                select(TOM:silt_clay)), 
                                y = sediments.sand.hab %>% pull(habitat), 
                                family = "multinomial", type.multinomial = "grouped")

plot(en.sediments.hab.sand, xvar = "lambda", label = TRUE, type.coef = "2norm")

cvfit.sediments.hab.sand <- cv.glmnet(x = as.matrix(sediments.sand.hab %>% select(TOM:silt_clay)),
                                      y = sediments.sand.hab %>% pull(habitat), 
                                      family="multinomial", type.multinomial = "grouped")

plot(cvfit.sediments.hab.sand)
```
No luck here - still too few replications, I guess. No convergence even after the maximum number of iterations.    
The lowest deviance is achieved with 4 explanatory variables - let's check them out.  
```{r coef_en_sediments_hab_sand}
coef(en.sediments.hab.sand, s = cvfit.sediments.hab.sand$lambda.min)
```

Test the model.  
```{r test_glm_en_sediments_hab_sand}
summary(glm(as.numeric(as.factor(habitat)) ~ TOM + moisture_content + gravel + silt_clay, data = sediments.sand.hab))
```
No significant variables - mostly expected, without convergence and all.   

More or less the same results with the habitats as dependent variable (with the same statistical problems).  



##### Seagrass stations - Burgas Bay (2013-2014)  
Now I'll analyze the seagrass stations - mostly focusing on the sediment parameters, because I strongly suspect the same piece of shit will happen if I try with the very much summarized water column variables.  

Filter water column data anyway, in case I decide to do something with it.     
```{r import_water_data_zostera}
## filter (manually) to get only the zostera 2013-2014 stations - mean data
(water.zostera <- water %>% 
    filter(station %in% c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo"))
)

## also filter the non-summarized water column data
(water.zostera.all <- water.all %>% 
    filter(station %in% c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo"))
)

```

Import the **summarized** sediment data (it also contains the heavy metals).   
```{r import_summary_sediment_data_zostera}
sediments.zostera <- read_csv(here(save.dir, "sediments_imputed_seagrass.csv"))

## split into sediment parameters sesnu stricto, and heavy metals
(heavy.metals.zostera <- sediments.zostera %>% 
    select(station:year, Cu:Ni) 
)

(sediments.zostera <- sediments.zostera %>% 
    select(-c(Cu:Ni))
)  
```

Add LUSI to the water column data for the seagrass stations.   
```{r lusi_zostera}
## match by station - only for the seagrass stations - the rows of x (the water column data) where there are matching values in y (LUSI) -> e.g. inner join 
(water.zostera <- inner_join(water.zostera, 
                             lusi %>% select(-watershed), 
                             by = "station")
)
```

Check the correlations here, too, just for the heck of it (correlations with only single values are just as meaningless as PCA)..  
```{r water_zostera_correlations}
Hmisc::rcorr(as.matrix(water.zostera %>% select(-station)), 
             type = "pearson")
```

Hm, no luck here: no signifcant correlations of LUSI with anything but the bottom O2, which itself is very unreliable. I suppose this difference with the sand stations is due to the fact that the "long-term" water column data for the seagrasses only spans 2013-2014/2015 - it's not even close to the monthly data available for the sand stations over 2009-2011, supplemented with some data from 2013-2014.  
In essence, the available water column data for the seagrasses doesn't really capture the anthropogenic eutrophication gradient (it's the same Burgas Bay gradient as the sand stations).      
Could also explain why there are very, very few significant correlations at all...  

OK, let's proceed with the sediment PCA. I'm not even going to bother eliminating highly correlated variables, that's how useless I think this whole exercise is.  
```{r pca_sediments_zostera}
# scale and center the data (different units), and add back the stations 
sediments.zostera.scaled <- scale(sediments.zostera %>% select(-c(station:habitat)), 
                                  center = TRUE, scale = TRUE)

sediments.zostera.scaled <- bind_cols(sediments.zostera %>% select(station),
                                      as.tibble(sediments.zostera.scaled))

## convert stations into factor, because for some stations there are more observations than for others, which causes the Investigate function to freak out later
sediments.zostera.scaled <- sediments.zostera.scaled %>% 
  mutate(station = factor(station, levels = c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo")))

sediments.zostera.pca <- PCA(sediments.zostera.scaled, scale.unit = FALSE, quali.sup = 1)

Investigate(sediments.zostera.pca, file = "pca_sediments_zostera_report.Rmd", document = "html_document", remove.temp = TRUE)
```

Report summary: While the amount of variation explained by the first two PCs is significant, the estimation of the right number of axis to interpret suggests to **not interpret the analysis at all**: the amount of inertia of the first axis is not higher than that obtained by the 0.95-quantile of random distributions (54.34% against 54.9%); therefore no axis is carrying real information.  
I am going to blame this on the singleton values for Vromos and Ropotamo (only sampled once each during the study period).   
Anyway, because the suggestion is based on a value actually very close to being significant, here's a very cautious, very tentative description of the first two dimensions, the clusters of individuals & the main explanatory variables.  

Dimension 1 opposes individuals such as 8 (Ropotamo - to the right of the graph, characterized by a strongly positive coordinate on the axis) to individuals such as 7 (Gradina - to the left of the graph, characterized by a strongly negative coordinate on the axis).
The group of individual 8 has high values for the variables mean_grain_size, sorting and gravel (strongest to weakest).  
The group of individual 7 has:
- high values for the variable sand.  
- low values for the variables moisture_content and silt_clay (weakest to strongest).  

Variables sorting, gravel and Ropotamo are highly correlated with this dimension (respective correlation of 0.95, 0.91, 0.91) - could summarize themselves the dimension 1.  

Dimension 2 opposes individuals such as 1, 2 and 3 (Poda - to the top of the graph, characterized by a strongly positive coordinate on the axis) to individuals such as ** and 7 (Gradina - to the bottom of the graph, characterized by a strongly negative coordinate on the axis).
The group of individuals 1, 2 and 3 has high values for the variables silt_clay and moisture_content (strongest to weakest).  
The group of individual 7 has:  
- high values for the variable sand.  
- low values for the variables moisture_content and silt_clay (weakest to strongest).  

Variables silt_clay and Poda are highly correlated with this dimension (respective correlation of 0.01, 0 - *wow..*). These variables could therefore summarize themselves the dimension 2.  

The classification made on individuals reveals **4 clusters**.  
Cluster 1 is made of individuals such as 7 (Gradina), with low values for the variable TOM.  
Cluster 2 is made of individuals (Otmanli - one of the samples) with variables whose values do not differ significantly from the mean.   
Cluster 3 is made of individuals such as 1, 2 and 3 (Poda, other Otmanli), with high values for the variables silt_clay and moisture_content (strongest to weakest).  
Cluster 4 is made of individuals such as 8 (Ropotamo), with high values for the variables mean_grain_size, sorting and gravel (strongest to weakest).  

In essence, based on the sediment structure and composition, Ropotamo is very different than the other seagrass stations - has coarser sediments, with more gravel and large mean grain size. The silt-clay and the TOM content are not so high, though - even though it could be expected, with the river mouth right there..   
Poda (and partially Otmanli) have very large silt-clay contents, which puts them in a group of their own. In passing, the two Otmanli values for the 2 years are very, very different...  
Gradina and Vromos are similar in sediment composition & structure - low silt-clay, high sand content.  

Also save the seagrass sediment PCA, despite its doubtful usability... 
```{r save_pca_sediments_zostera}
write_rds(sediments.zostera.pca, 
          here(save.dir, "pca_sediments_zostera.RDS"))
```


For consistency, I'll do a quick PCA on **non-summarized water column data** in seagrass.  
First - without removing any variables, even if they're highly inter-correlated.  
```{r pca_water_zostera_all}
## scale and center the data
water.zostera.all.scaled <- scale(water.zostera.all %>% select(-c(station:month)), 
                                  center = TRUE, scale = TRUE)

water.zostera.all.scaled <- bind_cols(water.zostera.all %>% select(station),
                                      as.tibble(water.zostera.all.scaled))

## convert stations into factor, because for some stations there are more observations than for others, which causes the Investigate function to freak out later
water.zostera.all.scaled <- water.zostera.all.scaled %>% 
  mutate(station = factor(station, levels = c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo")))
water.zostera.all.pca <- PCA(water.zostera.all.scaled, scale.unit = FALSE, quali.sup = 1)

Investigate(water.zostera.all.pca, 
            file = "pca_water_zostera_all_report.Rmd", document = "html_document", 
            out.selec = FALSE, # NB if outlier detection is performed, the function fails miserably, and I can't see a way to fix it 
            remove.temp = TRUE)  
```
OK, since the outlier check is omitted, the report shows that two rows with extreme values have a really high influence on the axes, the separation, etc. These are rows 18 (Poda) and 26 (Ropotamo). Let's see them:  
```{r water_zostera_all_outliers}
water.zostera.all %>% filter(row_number() %in% c(18, 26))
```

I'll remove them manually and try again.  
```{r pca_water_zostera_all_noout}
water.zostera.all.scaled.noout <- water.zostera.all.scaled %>%
  filter(!row_number() %in% c(18, 26))

water.zostera.all.scaled.noout.pca <- PCA(water.zostera.all.scaled.noout, scale.unit = FALSE, quali.sup = 1)

Investigate(water.zostera.all.scaled.noout.pca, 
            file = "pca_water_zostera_all_noout.Rmd", document = "html_document", 
            out.selec = FALSE, # NB if outlier detection is performed, the function fails miserably, and I can't see a way to fix it 
            remove.temp = TRUE)   
```

Great. Now I'll try it properly - I'll first remove the most correlated variables, because this leads to artificial inflation of the significance of representation (?).   
```{r filter_correlated_water_zostera}
# calculate the correlation matrix (on the numeric variables only)
water.zostera.all.cors <- cor(water.zostera.all %>% select(-c(station:month)))
  
# find and eliminate the highly correlated variables. NB names = FALSE, to return column index
highly.cor.water.zostera.all <- findCorrelation(water.zostera.all.cors, cutoff = 0.85)

(water.zostera.red <- water.zostera.all %>% 
    select(-c(station:month)) %>% # otherwise column indices don't match 
    select(-highly.cor.water.zostera.all)
)
```

```{r pca_water_zostera_red}
## scale and center the reduced dataset
water.zostera.red.scaled <- scale(water.zostera.red,
                                  center = TRUE, scale = TRUE)

water.zostera.red.scaled <- bind_cols(water.zostera.all %>% select(station),
                                      as.tibble(water.zostera.red.scaled))

## convert stations into factor, because for some stations there are more observations than for others, which causes the Investigate function to freak out later
water.zostera.red.scaled <- water.zostera.red.scaled %>% 
  mutate(station = factor(station, levels = c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo")))

## filter out the two outliers
water.zostera.red.scaled <- water.zostera.red.scaled %>% 
  filter(!row_number() %in% c(18, 26))

water.zostera.red.pca <- PCA(water.zostera.red.scaled, scale.unit = FALSE, quali.sup = 1)

Investigate(water.zostera.red.pca, 
            file = "pca_water_zostera_red_report.Rmd", document = "html_document", 
            out.selec = FALSE, # NB if outlier detection is performed, the function fails miserably, and I can't see a way to fix it 
            remove.temp = TRUE)  
```

Same for the **sediments - with all available data**.   
```{r filter_correlated_sediments_zostera_all}
## remove the heavy metals, which are still in the dataset for some reason
sediments.zostera.all.sub <- sediments.zostera.all %>% 
  select(-habitat, -c(Cu:Ni))

## calculate the correlation matrix (on the numeric variables only)
sediments.zostera.all.cors <- cor(sediments.zostera.all.sub %>% select(-c(station:year)))
  
## find and eliminate the highly correlated variables. NB names = FALSE, to return column index
highly.cor.sediments.zostera.all.sub <- findCorrelation(sediments.zostera.all.cors, cutoff = 0.85)

(sediments.zostera.red <- sediments.zostera.all.sub %>% 
    select(-c(station:year)) %>% # otherwise column indices don't match 
    select(-highly.cor.sediments.zostera.all.sub)
)
```


```{r pca_sediments_zostera_red}
## scale and center the reduced dataset
sediments.zostera.red.scaled <- scale(sediments.zostera.red,
                                      center = TRUE, scale = TRUE)

sediments.zostera.red.scaled <- bind_cols(sediments.zostera.all %>% select(station),
                                          as.tibble(sediments.zostera.red.scaled))

## convert stations into factor, because for some stations there are more observations than for others, which causes the Investigate function to freak out later
sediments.zostera.red.scaled <- sediments.zostera.red.scaled %>% 
  mutate(station = factor(station, levels = c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo")))

sediments.zostera.red.pca <- PCA(sediments.zostera.red.scaled, scale.unit = FALSE, quali.sup = 1)

Investigate(sediments.zostera.red.pca, 
            file = "pca_sediments_zostera_red_report.Rmd", document = "html_document", 
            out.selec = FALSE, # NB if outlier detection is performed, the function fails miserably, and I can't see a way to fix it 
            remove.temp = TRUE)  
```
Here - no luck again: too little variability is explained by the PCs - no real information carried by this PCA, either.   

OK, one more to go: **seagrass parameters - again, using all available data**.  
```{r filter_correlated_seagrass_params_zostera}
## calculate the correlation matrix (on the numeric variables only)
seagrass.all.cors <- cor(seagrass.all.clean %>% select(-c(station:replicate)))
  
## find and eliminate the highly correlated variables. NB names = FALSE, to return column index
highly.cor.seagrass.all <- findCorrelation(seagrass.all.cors, cutoff = 0.85)

(seagrass.red <- seagrass.all.clean %>% 
    select(-c(station:replicate)) %>% # otherwise column indices don't match 
    select(-highly.cor.seagrass.all)
)
```
All right - apparently the seagrass parameters are not so inter-correlated after all...   
```{r pca_seagrass_params_zostera}
## scale and center the reduced dataset
seagrass.red.scaled <- scale(seagrass.red,
                             center = TRUE, scale = TRUE)

seagrass.red.scaled <- bind_cols(seagrass.all.clean %>% select(station),
                                 as.tibble(seagrass.red.scaled))

## convert stations into factor, because for some stations there are more observations than for others, which causes the Investigate function to freak out later
seagrass.red.scaled <- seagrass.red.scaled %>% 
  mutate(station = factor(station, levels = c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo")))

seagrass.red.pca <- PCA(seagrass.red.scaled, scale.unit = FALSE, quali.sup = 1)

Investigate(seagrass.red.pca, 
            file = "pca_seagrass_params_zostera_red_report.Rmd", document = "html_document", 
            out.selec = FALSE, # NB if outlier detection is performed, the function fails miserably, and I can't see a way to fix it 
            remove.temp = TRUE)  
```


###### **Elastic net - seagrasses 2013-14.**    
Learning from the sand stations, I'll try it on the raw (non-summarized) data.  
Starting with water column crap.  
```{r en_water_zostera}
## transform station to factor
water.zostera.all <- water.zostera.all %>% 
  mutate(station = factor(station, levels = c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo")))

## perform the elastic net shit, excluding the Secchi depth - too many missing values 
en.water.st.zostera <- glmnet(x = as.matrix(water.zostera.all %>% select(chl_a:seston)), 
                           y = water.zostera.all %>% pull(station), 
                           family = "multinomial", type.multinomial = "grouped")

plot(en.water.st.zostera, xvar = "lambda", label = TRUE, type.coef = "2norm")


cvfit.water.st.zostera <- cv.glmnet(x = as.matrix(water.zostera.all %>% select(chl_a:seston)),
                                 y = water.zostera.all %>% pull(station), 
                                 family="multinomial", type.multinomial = "grouped")

plot(cvfit.water.st.zostera)
```

Again, multiple complaints - see part about sediments in sand stations. Probably come from insufficent replication.  

Let's see which variables are the most important according to the elastic net.  
```{r coef_en_water_zostera}
coef(en.water.st.zostera, s = cvfit.water.st.zostera$lambda.min)
```
Goody - seston is the only significant variable according to this analysis... Still, better than before, when there were absolutely none.    
Let's try the model, then.  
```{r test_glm_en_water_zostera}
summary(glm(as.numeric(station) ~ seston, data = water.zostera.all))
```
So seston is not even significant here, and the reduction in deviance is not really significant...  
Let's try all variables, then, just to see what comes up.  
```{r test2_glm_en_water_zostera}
summary(glm(as.numeric(station) ~ chl_a + Ninorg + NH4 + NO3 + Ntotal + PO4 + seston, data = water.zostera.all))
```
Seston, at the boundary of significance... Load of shit, all of it.  

OK - let's try again with the **sediment parameters minus the heavy metals**.   
In this case, I am going to go back and look at the sediment data for the rest of the stations (there were 2 stations in each seagrass meadow at each sampling, and there is data for those, too).   
```{r en_sediments_zostera}
## import the non-summarized sediment data for the zostera stations
(sediments.zostera.all <- read_csv(here(save.dir, "sediments_seagrass_raw_clean.csv"))
)  

## make station a factor 
sediments.zostera.all <- sediments.zostera.all %>% 
  mutate(station = factor(station, levels = c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo")))

en.sediments.st.zostera <- glmnet(x = as.matrix(sediments.zostera.all %>% select(TOM:silt_clay)), 
                           y = sediments.zostera.all %>% pull(station), 
                           family = "multinomial", type.multinomial = "grouped")

plot(en.sediments.st.zostera, xvar = "lambda", label = TRUE, type.coef = "2norm")

cvfit.sediments.st.zostera <- cv.glmnet(x = as.matrix(sediments.zostera.all %>% select(TOM:silt_clay)),
                                 y = sediments.zostera.all %>% pull(station), 
                                 family="multinomial", type.multinomial = "grouped")

plot(cvfit.sediments.st.zostera)
```

It still complains, doesn't want to assess the fit. 
I'm going to exclude Vromos and Ropotamo (only 2 observations each) and see if that changes anything..  
```{r en_sediments_zostera_2}
## filter out Vromos and Ropotamo
(sediments.zostera.all.sub <- sediments.zostera.all %>% 
   filter(station != "Ropotamo", station != "Vromos") %>%
   mutate(station = factor(station, levels = c("Poda", "Otmanli", "Gradina")))
)


en.sediments.st.zostera.2 <- glmnet(x = as.matrix(sediments.zostera.all.sub %>%  select(TOM:silt_clay)), 
                                    y = sediments.zostera.all.sub %>% pull(station), 
                                    family = "multinomial", type.multinomial = "grouped")

plot(en.sediments.st.zostera.2, xvar = "lambda", label = TRUE, type.coef = "2norm")

cvfit.sediments.st.zostera.2 <- cv.glmnet(x = as.matrix(sediments.zostera.all.sub %>% select(TOM:silt_clay)),
                                          y = sediments.zostera.all.sub %>% pull(station), 
                                          family="multinomial", type.multinomial = "grouped")

plot(cvfit.sediments.st.zostera.2)
```

Well wouldn't you know it - it works this time (with 3 out of the 5 stations)!  
Check out to which parameters we owe this immense honor..  
```{r coef_en_sediments_zostera_2}
coef(en.sediments.st.zostera.2, s = cvfit.sediments.st.zostera.2$lambda.min)
```
OK, not too terrible, all things considered... Let's plug them in a model and see what it says.   
```{r test_glm_en_sediments_zostera}
summary(glm(as.numeric(as.factor(station)) ~ TOM + moisture_content + sorting + silt_clay, data = sediments.zostera.all.sub))
```
So the moisture content and the silt & clay (maybe the TOM, a little)..  

Let's play with the **seagrass parameters**. I'm not holding my breath, though.  
```{r import_seagrass_params_zostera}
## import the non-summarized data first 
(seagrass.all <- read_csv(here(save.dir, "seagrass_all_stations.csv"))
 )

## remove the number from the station names
seagrass.all.clean <- seagrass.all %>% 
  mutate(station = str_extract(station, "[^\\d]+"))

## filter only the 2013-2014 stations and convert station to factor
(seagrass.all.clean <- seagrass.all.clean %>% 
    filter(station %in% c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo")) %>% 
    mutate(station = factor(station, levels = c("Poda", "Otmanli", "Vromos", "Gradina", "Ropotamo")))
)  
```

Perform the elastic net variable selection.  
```{r en_seagrass_params_zostera}
en.seagrass.st.zostera <- glmnet(x = as.matrix(seagrass.all.clean %>%  select(shoot_count:bg_biomass_wet)),
                                 y = seagrass.all.clean %>% pull(station), 
                                 family = "multinomial", type.multinomial = "grouped")

plot(en.seagrass.st.zostera, xvar = "lambda", label = TRUE, type.coef = "2norm")

cvfit.seagrass.st.zostera <- cv.glmnet(x = as.matrix(seagrass.all.clean %>% select(shoot_count:bg_biomass_wet)),
                                       y = seagrass.all.clean %>% pull(station),
                                       family="multinomial", type.multinomial = "grouped")

plot(cvfit.seagrass.st.zostera)
```
Still it doesn't like it... no convergence of lambda after the max number of iterations. Sweet...   
From the plot of the fit it looks like all 3 parameters combined would provide the best explanatory power, but who knows...   
```{r test_glm_seagrass_params_zostera}
summary(glm(as.numeric(as.factor(station)) ~ shoot_count + ag_biomass_wet + bg_biomass_wet, data = seagrass.all.clean))
```
*Maybe* just the below-ground wet biomass...   

**For seagrass samples, it looks like there are too few observations of the environmental parameters for us to be able to apply the elastic net method of variable selection. For that matter, the PCA on these parameters is not really meaningful either, esp. for the sediments.**   


##### Sozopol Bay, 2012  
Starting with the water column parameters. Here at least there are some more - thanks to the 2009-2011 project.  
However, I am going to work with the non-summarized data, because I don't have any more nerves for invalid analyses.  
```{r filter_water_data_2012}
## from the long-term non-summarized water column parameters
(water.2012 <- water.all %>% 
    filter(station %in% c("Konski", "Ribka", "Gradina"))
)
```
There is no point to add LUSI here - the entire Sozopol Bay falls within one watershed, so only one value.  

 
```{r pca_water_2012}
## scale and center the data (different units), and add back the stations 
water.2012.scaled <- scale(water.2012 %>% select(chl_a:secchi), center = TRUE, scale = TRUE)

water.2012.scaled <- bind_cols(water.2012 %>% select(station), 
                               as.tibble(water.2012.scaled))

## make station a factor
water.2012.scaled <- water.2012.scaled %>% 
  mutate(station = factor(station, levels = c("Konski", "Ribka", "Gradina")))

## perform PCA with FactoMineR - it's equivalent to the base version, anyway, but the visualization expects a particular structure of the results, so easier to do it this way. 
water.2012.pca <- PCA(water.2012.scaled,
                      scale.unit = FALSE, 
                      quali.sup = 1,
                      graph = FALSE)

## display the summary and biplot
summary(water.2012.pca)

(plot.water.2012.pca <- fviz_pca_biplot(water.2012.pca, axes = c(1, 2), 
                                        label = "var", 
                                        col.var = "cos2", gradient.cols = c("skyblue", "navyblue", "red"),
                                        repel = TRUE)
)

ggsave(here(figures.dir, "pca_water_2012.png"), plot.water.2012.pca, dpi = 300)
```
This, however, is without first filtering the very much correlated variables.  

Generate a report on the PCA with FactoInvestigate.  
```{r report_pca_water_2012}
Investigate(water.2012.pca, file = "pca_water_2012_report.Rmd", document = "html_document", remove.temp = TRUE)
```
OK this bullshit doesn't work, I don't know why and I don't care - something to do with outlier detection. That's why I hate complicated black box functions.  
Moving right along to elastic net, which I would trust more in any case.  
```{r en_water_2012}
## filter out one row with NaN in NH4
water.2012.sub <- water.2012 %>% 
  filter(!is.nan(NH4))

en.water.st.2012 <- glmnet(x = as.matrix(water.2012.sub %>% select(chl_a:seston)), 
                           y = water.2012.sub %>% pull(station), 
                           family = "multinomial")

plot(en.water.st.2012, xvar = "lambda", label = TRUE, type.coef = "2norm")

## check the fit
cvfit.water.st.2012 <- cv.glmnet(x = as.matrix(water.2012.sub %>% select(chl_a:seston)),
                                 y = water.2012.sub %>% pull(station), 
                                 family="multinomial")

plot(cvfit.water.st.2012)

```

```{r}
coef(en.water.st.2012, s = cvfit.water.st.2012$lambda.min)
```


No convergence for lambda, even after the maximum number of iterations (10000).. Isn't it sweet.  



